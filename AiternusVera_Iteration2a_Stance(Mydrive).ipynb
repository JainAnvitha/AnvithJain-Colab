{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "AiternusVera_Iteration2a_Stance(Mydrive).ipynb",
      "provenance": [],
      "collapsed_sections": [
        "nGrOKai7xvDL",
        "aEJ9zjX6xvDS",
        "Y6O4CRrMxvDT",
        "m2UibiXkxvDu",
        "e-WoQlqDxvDz",
        "X4jGsl2SxvD1",
        "lCsslHePxvD2",
        "ZWzI-ZMDxvD4",
        "QAxq-wlxxvD4",
        "ls5D4OH2xvD7",
        "dB2I8ahRxvD9",
        "fNRPP03exvD_",
        "XyegvlJAxvEC",
        "C0rQHqcPxvED",
        "0o-sCgyhxvEF",
        "S9tNn2SrxvEG",
        "ireF8K1sxvEI",
        "vEMbf252xvEK",
        "8Zb41E_8xvEL",
        "nUwRvaVRxvEN",
        "dzZ1mRgRxvEO",
        "1CCFvz6MxvEP",
        "O5BPCW_8xvEU",
        "Gm-pOW5vxvEi",
        "kLipfgWdxvEm",
        "IVV6-_x7xvEp",
        "q7VLPR_rxvEw",
        "k9L5vxKaxvE7",
        "81NutCZIxvE_",
        "s9B6C4wuxvFE",
        "pqyv5Tv2xvFE",
        "TLGZt9-WxvFI",
        "iL5xmHEexvFI",
        "tP4DZzdUxvFP",
        "cNCZr--GxvFU",
        "RaBzEJX8xvFa",
        "zR5c40wcxvFd",
        "ETx0Pdj0xvFe"
      ],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JainAnvitha/AnvithJain-Colab/blob/master/AiternusVera_Iteration2a_Stance(Mydrive).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIRWHPxhxvCx",
        "colab_type": "text"
      },
      "source": [
        "# Alternus Vera \n",
        "\n",
        " \n",
        "\n",
        "-----\n",
        "\n",
        "GitHub URL: \n",
        "\n",
        "\n",
        "### Liar Liar Pants on Fire Dataset Description \n",
        "- It has 3 files test, training and valid.\n",
        "- Each file has 14 columns\n",
        "    \n",
        "    Column 1: the ID of the statement ([ID].json).\n",
        "    \n",
        "    Column 2: the label.\n",
        "    \n",
        "    Column 3: the statement.\n",
        "    \n",
        "    Column 4: the subject(s).\n",
        "    \n",
        "    Column 5: the speaker.\n",
        "    \n",
        "    Column 6: the speaker's job title.\n",
        "    \n",
        "    Column 7: the state info.\n",
        "    \n",
        "    Column 8: the party affiliation.\n",
        "    \n",
        "    Column 9-13: the total credit history count, including the current statement.\n",
        "    \n",
        "    Column 14: the context (venue / location of the speech or statement).\n",
        "\n",
        "### Process \n",
        "- Load the Data\n",
        "- Distillation Process\n",
        "    - Data Cleaning and Text Preprocessing\n",
        "    - Visualization\n",
        "- **Feature 1 :** Sentiment Analysis \n",
        "- **Feature 2 :** LDA Topic Modelling\n",
        "- **Feature 3 :** Sensationalism \n",
        "- **Feature 4 :** Political Affiliation \n",
        "- **Feature 5 :** Clickbait \n",
        "- **Feature 6 :** Spam \n",
        "- **Feature 7 :** Author Credibility \n",
        "- **Feature 8 :** Source Reputation\n",
        "- **Feature 9 :** Content Length     \n",
        "- **Feature 10 :** Word Frequency \n",
        "- Vector Classification Modeling \n",
        "- Ranking and Importance\n",
        "- Merge all features and individual contributions\n",
        "- Form Polynomial Equation \n",
        "    \n",
        "\n",
        "### Feature Selection\n",
        "**List top Features Selected based on research articles**\n",
        "\n",
        "\n",
        "\n",
        "### Team Contributions example:\n",
        "\n",
        "|Features  |  Member |\n",
        "|-----|-----|\n",
        "| Stance                        |  Anvitha Shubhaveer Jain |  \n",
        "| Feature name(s)                 |  Member name(s) | \n",
        "| Feature name(s)                   |  Member name(s)  |   \n",
        "| Feature name(s)                             |  Member name(s) |\n",
        "\n",
        " \n",
        "#### Enrichment Dataset Details\n",
        "\n",
        "- SenticNet5 sensational words corpus\n",
        "- Google News 3million words corpus for spell check\n",
        "- Sensational Words Dictionary \n",
        "- PoliticalFact Fake news and Real News Content \n",
        "- Clickbait and non_clickbait datasets\n",
        "- Spam Dictionary \n",
        "\n",
        "#### Libraries Used \n",
        "\n",
        "- NLTK \n",
        "- Gensim \n",
        "- Numpy\n",
        "- Pandas\n",
        "- CSV\n",
        "- WordCloud\n",
        "- Seaborn\n",
        "- Scipy\n",
        "- Regualr Expression\n",
        "- Matplotlib\n",
        "- Sklearn \n",
        "\n",
        "\n",
        "#### What did I try and What worked? \n",
        "\n",
        "> Explain your work ...\n",
        "\n",
        "#### What did not work?\n",
        "\n",
        "> Explain your work ...\n",
        "\n",
        "\n",
        "#### What alternatives did you try?\n",
        "\n",
        "> Explain your work \n",
        "\n",
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNz9c8DhxvCz",
        "colab_type": "text"
      },
      "source": [
        "### Reading the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9KXjaztxvC0",
        "colab_type": "code",
        "outputId": "1733f4cd-e55f-4555-cd9f-322913a4d064",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv\n",
        "import gensim\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.pipeline import Pipeline\n",
        "from nltk.corpus import stopwords\n",
        "from string import punctuation\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import sparse\n",
        "# Code source: https://degravek.github.io/project-pages/project1/2017/04/28/New-Notebook/\n",
        "# Dataset from Chakraborty et al. (https://github.com/bhargaviparanjape/clickbait/tree/master/dataset)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JMEBBqhyQLF",
        "colab_type": "code",
        "outputId": "896de205-02ce-4bc2-d918-cc8a13bf1d7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3iG4JYHxvC3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read the test, training and valid data from files\n",
        "# Header = 0 indicates that the first line of the file contains column names,\n",
        "# As there is no Header, create a column names for each column in the dataset\n",
        "# delimiter = \\t indicates that the fields are seperated by tabs, and \n",
        "\n",
        "\n",
        "test_filename = '/content/drive/My Drive/MLFall2019/crimerate-seers/Datasets/test.tsv'\n",
        "train_filename = '/content/drive/My Drive/MLFall2019/crimerate-seers/Datasets/train.tsv'\n",
        "valid_filename = '/content/drive/My Drive/MLFall2019/crimerate-seers/Datasets/valid.tsv'\n",
        "\n",
        "colnames = ['jsonid', 'label', 'headline_text', 'subject', 'speaker', 'speakerjobtitle', 'stateinfo','partyaffiliation', 'barelytruecounts', 'falsecounts','halftruecounts','mostlytrueocunts','pantsonfirecounts','context']\n",
        "\n",
        "train_news = pd.read_csv(train_filename, sep='\\t', names = colnames, error_bad_lines=False)\n",
        "test_news = pd.read_csv(test_filename, sep='\\t', names = colnames, error_bad_lines=False)\n",
        "valid_news = pd.read_csv(valid_filename, sep='\\t', names = colnames, error_bad_lines=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "-TTPPIvUxvC5",
        "colab_type": "code",
        "outputId": "13c8ad0f-c741-4551-a40e-e950142ceefd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        }
      },
      "source": [
        "# Display check the dimensions and the first 2 rows of the file.\n",
        "\n",
        "print('train dim:',train_news.shape, 'test dim:', test_news.shape)\n",
        "train_news.iloc[0:2]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train dim: (10240, 14) test dim: (1267, 14)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>jsonid</th>\n",
              "      <th>label</th>\n",
              "      <th>headline_text</th>\n",
              "      <th>subject</th>\n",
              "      <th>speaker</th>\n",
              "      <th>speakerjobtitle</th>\n",
              "      <th>stateinfo</th>\n",
              "      <th>partyaffiliation</th>\n",
              "      <th>barelytruecounts</th>\n",
              "      <th>falsecounts</th>\n",
              "      <th>halftruecounts</th>\n",
              "      <th>mostlytrueocunts</th>\n",
              "      <th>pantsonfirecounts</th>\n",
              "      <th>context</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2635.json</td>\n",
              "      <td>false</td>\n",
              "      <td>Says the Annies List political group supports ...</td>\n",
              "      <td>abortion</td>\n",
              "      <td>dwayne-bohac</td>\n",
              "      <td>State representative</td>\n",
              "      <td>Texas</td>\n",
              "      <td>republican</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>a mailer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10540.json</td>\n",
              "      <td>half-true</td>\n",
              "      <td>When did the decline of coal start? It started...</td>\n",
              "      <td>energy,history,job-accomplishments</td>\n",
              "      <td>scott-surovell</td>\n",
              "      <td>State delegate</td>\n",
              "      <td>Virginia</td>\n",
              "      <td>democrat</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>a floor speech.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       jsonid      label  ... pantsonfirecounts          context\n",
              "0   2635.json      false  ...               0.0         a mailer\n",
              "1  10540.json  half-true  ...               0.0  a floor speech.\n",
              "\n",
              "[2 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSNs7Xv1xvC7",
        "colab_type": "text"
      },
      "source": [
        "## Data Cleaning and Text Preprocessing \n",
        "\n",
        "*Steps included in the preprocessing:*\n",
        "- Remove Special Characters and Punctuations\n",
        "- Lower case the news\n",
        "- Tokenization\n",
        "- Remove Stop Words\n",
        "- Lemmatization\n",
        "- Stemming \n",
        "- Spell Check "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s67URXP-xvC7",
        "colab_type": "text"
      },
      "source": [
        "###  Putting It All Together \n",
        "\n",
        "To make the code reusable, we need to create a function that can be called many times."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woG2-wXvxvC8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "\n",
        "def cleaning(raw_news):\n",
        "    import nltk\n",
        "    \n",
        "    # 1. Remove non-letters/Special Characters and Punctuations\n",
        "    news = re.sub(\"[^a-zA-Z]\", \" \", raw_news)\n",
        "    \n",
        "    # 2. Convert to lower case.\n",
        "    news =  news.lower()\n",
        "    \n",
        "    # 3. Tokenize.\n",
        "    news_words = nltk.word_tokenize( news)\n",
        "    \n",
        "    # 4. Convert the stopwords list to \"set\" data type.\n",
        "    stops = set(nltk.corpus.stopwords.words(\"english\"))\n",
        "    \n",
        "    # 5. Remove stop words. \n",
        "    words = [w for w in  news_words  if not w in stops]\n",
        "    \n",
        "    # 6. Lemmentize \n",
        "    wordnet_lem = [ WordNetLemmatizer().lemmatize(w) for w in words ]\n",
        "    \n",
        "    # 7. Stemming\n",
        "    stems = [nltk.stem.SnowballStemmer('english').stem(w) for w in wordnet_lem ]\n",
        "    \n",
        "    # 8. Join the stemmed words back into one string separated by space, and return the result.\n",
        "    return \" \".join(stems)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "9gHkWIcDxvC9",
        "colab_type": "code",
        "outputId": "d8c7ec15-d7f4-4d71-adcf-90af4259d547",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "import time\n",
        "# clean training and test data \n",
        "# create new column \"tokenized\"\n",
        "t1 = time.time()\n",
        "\n",
        "# Add the processed data to the original data. \n",
        "# Perhaps using apply function would be more elegant and concise than using for loop\n",
        "train_news['clean'] = train_news[\"headline_text\"].apply(cleaning) \n",
        "\n",
        "t2 = time.time()\n",
        "print(\"\\nTime to clean, tokenize and stem train data: \\n\", len(train_news), \"news:\", (t2-t1)/60, \"min\")\n",
        "\n",
        "t1 = time.time()\n",
        "test_news['clean'] = test_news[\"headline_text\"].apply(cleaning)\n",
        "\n",
        "t2 = time.time()\n",
        "print(\"\\n\\nTime to clean, tokenize and stem test data: \\n\", len(test_news), \"news:\", (t2-t1)/60, \"min\")\n",
        "\n",
        "t1 = time.time()\n",
        "valid_news['clean'] = valid_news[\"headline_text\"].apply(cleaning)\n",
        "\n",
        "t2 = time.time()\n",
        "print(\"\\n\\nTime to clean, tokenize and stem valid data: \\n\", len(valid_news), \"news:\", (t2-t1)/60, \"min\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "\n",
            "Time to clean, tokenize and stem train data: \n",
            " 10240 news: 0.13416224320729572 min\n",
            "\n",
            "\n",
            "Time to clean, tokenize and stem test data: \n",
            " 1267 news: 0.014386336008707682 min\n",
            "\n",
            "\n",
            "Time to clean, tokenize and stem valid data: \n",
            " 1284 news: 0.014113938808441162 min\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRv1X_gvxvC_",
        "colab_type": "text"
      },
      "source": [
        "### [Google News corpus word2vec](http://mccormickml.com/2016/04/12/googles-pretrained-word2vec-model-in-python/)\n",
        "\n",
        "### Spell Check \n",
        "\n",
        "-  You can download the pre-trained model [**here**](https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit)\n",
        "\n",
        "- Or clone it from GitHub [**GoogleNews-vectors-negative300**](https://github.com/mmihaltz/word2vec-GoogleNews-vectors)\n",
        "\n",
        "> It’s 1.5GB! It includes word vectors for a vocabulary of 3 million words and phrases that they trained on roughly 100 billion words from a Google News dataset. The vector length is 300 features.\n",
        "\n",
        "**3 million words * 300 features * 4bytes/feature = ~3.35GB**\n",
        "\n",
        "> This file consist of the word2vec -  pre-trained Google News corpus (3 billion running words) to word vector model (3 million 300-dimension English word vectors).\n",
        "\n",
        "> Look at the [**vocabulory list**](https://github.com/chrisjmccormick/inspect_word2vec/tree/master/vocabulary) used to train this model. Each text file contains 100,000 entries from the model. \n",
        "\n",
        "\n",
        ">  There are few things that this dataset contains and not. It has stop words like  “the”, “also”, “should” and does not have stop words like “a”, “and”, “of”. As I have removed the stop words the complexity is reduced as there is no need to check the spelling for stop words. \n",
        "\n",
        "> It does have numbers but in the form of entried wiht #. e.g., you won’t find “100”. But it does include entries like “###MHz_DDR2_SDRAM”. \n",
        "\n",
        "The model used [**WinPython-64bit-2.7.10.3**](https://winpython.github.io/) for efficient python distribution on Windows system. Helps to run the scripts in batches. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C43YnofVxvDA",
        "colab_type": "code",
        "outputId": "f074b491-5145-469c-ee3f-c53572981afd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        }
      },
      "source": [
        "model = gensim.models.KeyedVectors.load_word2vec_format('input_data/GoogleNews-vectors-negative300.bin.gz', binary=True)\n",
        "words = model.index2word\n",
        "\n",
        "w_rank = {}\n",
        "for i,word in enumerate(words):\n",
        "    w_rank[word] = i\n",
        "\n",
        "WORDS = w_rank"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-2fd59537c2fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKeyedVectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_word2vec_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'input_data/GoogleNews-vectors-negative300.bin.gz'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex2word\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mw_rank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mload_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype)\u001b[0m\n\u001b[1;32m   1436\u001b[0m         return _load_word2vec_format(\n\u001b[1;32m   1437\u001b[0m             \u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode_errors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0municode_errors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1438\u001b[0;31m             limit=limit, datatype=datatype)\n\u001b[0m\u001b[1;32m   1439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1440\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_keras_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_embeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/utils_any2vec.py\u001b[0m in \u001b[0;36m_load_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loading projection weights from %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmart_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m         \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_unicode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# throws for invalid file format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36msmart_open\u001b[0;34m(uri, mode, **kw)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m     return open(uri, mode, ignore_ext=ignore_extension,\n\u001b[0;32m--> 458\u001b[0;31m                 transport_params=transport_params, **scrubbed_kwargs)\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(uri, mode, buffering, encoding, errors, newline, closefd, opener, ignore_ext, transport_params)\u001b[0m\n\u001b[1;32m    350\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m         \u001b[0mbinary_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m     \u001b[0mbinary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open_binary_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransport_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mignore_ext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0mdecompressed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36m_open_binary_stream\u001b[0;34m(uri, mode, transport_params)\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparsed_uri\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscheme\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"file\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m             \u001b[0mfobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_uri\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muri_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mparsed_uri\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscheme\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msmart_open_ssh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSCHEMES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'input_data/GoogleNews-vectors-negative300.bin.gz'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqTZT-ABxvDB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "def words(text): return re.findall(r'\\w+', text.lower())\n",
        "\n",
        "def P(word, N=sum(WORDS.values())): \n",
        "    \"Probability of `word`.\"\n",
        "    return - WORDS.get(word, 0)\n",
        "\n",
        "def correction(word): \n",
        "    \"Most probable spelling correction for word.\"\n",
        "    return max(candidates(word), key=P)\n",
        "\n",
        "def candidates(word): \n",
        "    \"Generate possible spelling corrections for word.\"\n",
        "    return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])\n",
        "\n",
        "def known(words): \n",
        "    \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
        "    return set(w for w in words if w in WORDS)\n",
        "\n",
        "def edits1(word):\n",
        "    \"All edits that are one edit away from `word`.\"\n",
        "    letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
        "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
        "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
        "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
        "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
        "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
        "    return set(deletes + transposes + replaces + inserts)\n",
        "\n",
        "def edits2(word): \n",
        "    \"All edits that are two edits away from `word`.\"\n",
        "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uFVy0KwxvDD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def spell_checker(text):\n",
        "    all_words = re.findall(r'\\w+', text.lower()) # split sentence to words\n",
        "    spell_checked_text  = []\n",
        "    for i in range(len(all_words)):\n",
        "        spell_checked_text.append(correction(all_words[i]))\n",
        "    return ' '.join(spell_checked_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLlDw1DUxvDE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Before: \\n\", train_news['clean'][0] )\n",
        "t1 = time.time()\n",
        "train_news['clean'] = train_news['clean'].apply(spell_checker)\n",
        "t2 = time.time()\n",
        "print(\"\\nTime to spell check the train data: \\n\", len(train_news), \"news:\", (t2-t1)/60, \"min\")\n",
        "\n",
        "print(\"\\nAfter: \\n\",train_news['clean'][0] )\n",
        "train_news.head(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFgp6P_vxvDG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t1 = time.time()\n",
        "test_news['clean'] = test_news['clean'].apply(spell_checker)\n",
        "test_news.head(5)\n",
        "t2 = time.time()\n",
        "print(\"\\nTime to spell check the test data: \\n\", len(test_news), \"news:\", (t2-t1)/60, \"min\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_yjjFKbxvDI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t1 = time.time()\n",
        "valid_news['clean'] = valid_news['clean'].apply(spell_checker)\n",
        "valid_news.head(5)\n",
        "t2 = time.time()\n",
        "print(\"\\nTime to spell check the valid data: \\n\", len(valid_news), \"news:\", (t2-t1)/60, \"min\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ng0jVQ-3xvDJ",
        "colab_type": "text"
      },
      "source": [
        "##### Saved the trained dataset into a seperate CSV file "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBl26Z3xxvDK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_news.to_csv(\"input_data/train_processed.csv\", sep=',')\n",
        "test_news.to_csv(\"input_data/test_processed.csv\", sep=',')\n",
        "valid_news.to_csv(\"input_data/valid_processed.csv\", sep=',')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGrOKai7xvDL",
        "colab_type": "text"
      },
      "source": [
        "### Visualization \n",
        "\n",
        "#### WordCloud \n",
        "\n",
        "> As a tool for visualization by using the frequency of words appeared in text, we use WordCloud. Note that it can give more information and insight of texts by analyzing correlations and similarities between words rather than analyzing texts only by the frequency of words appeared; however, it can give you some general shape of what this text is about quickly and intuitively."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zG2Rw8s2xvDM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from wordcloud import WordCloud, STOPWORDS\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "0qq2gTEpxvDN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cloud(data,backgroundcolor = 'white', width = 800, height = 600):\n",
        "    wordcloud = WordCloud(stopwords = STOPWORDS, background_color = backgroundcolor,\n",
        "                         width = width, height = height).generate(data)\n",
        "    plt.figure(figsize = (15, 10))\n",
        "    plt.imshow(wordcloud)\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "    \n",
        "cloud(' '.join(train_news['clean']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m757psYAxvDP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cloud(' '.join(test_news['clean']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yI92UU93xvDR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cloud(' '.join(valid_news['clean']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEJ9zjX6xvDS",
        "colab_type": "text"
      },
      "source": [
        "#### Inferences from visulaization: \n",
        "- The large words are the words that are frequently appeared in the text/corpus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6O4CRrMxvDT",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# Feature 1: Sentiment analysis \n",
        "\n",
        "#### Using Vader Sentiment Analyser\n",
        "\n",
        "##### [Sentiment Intensity Analyzer](http://t-redactyl.io/blog/2017/04/using-vader-to-handle-sentiment-analysis-with-social-media-text.html)\n",
        "\n",
        "\n",
        "> VADER, or the **Valence Aware Dictionary and sEntiment Reasoner** has created a package that performes sentiment analysis using the polarity-based, where pieces of texts are classified as either positive or negative, or valence-based, where the intensity of the sentiment is taken into account. For example, the words ‘good’ and ‘excellent’ would be treated the same in a polarity-based approach, whereas ‘excellent’ would be treated as more positive than ‘good’ in a valence-based approach\n",
        "\n",
        "- It is based on lexicons of sentiment-related word.\n",
        "- The first three, positive, neutral and negative, represent the proportion of the text that falls into those categories.\n",
        "- The final metric, the compound score, is the sum of all of the lexicon ratings which have been standardised to range between -1 and 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6d-pZyqxvDT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "import nltk.sentiment\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "senti = nltk.sentiment.vader.SentimentIntensityAnalyzer()\n",
        "\n",
        "def print_sentiment_scores(sentence):\n",
        "    snt = senti.polarity_scores(sentence)\n",
        "    print(\"{:-<40} \\n{}\".format(sentence, str(snt)))\n",
        "    \n",
        "print_sentiment_scores(train_news['clean'][0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDAmu4eOxvDV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_vader_polarity(snt):\n",
        "    if not snt:\n",
        "        return None\n",
        "    elif snt['neg'] > snt['pos'] and snt['neg'] > snt['neu']:\n",
        "        return -1\n",
        "    elif snt['pos'] > snt['neg'] and snt['pos'] > snt['neu']:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJY0URdLxvDY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Function to determine if a text is negative(-1) or postive (1) or neutral (0)\n",
        "def get_polarity_type(sentence):\n",
        "    sentimentVector = []\n",
        "    snt = senti.polarity_scores(sentence)\n",
        "    sentimentVector.append(get_vader_polarity(snt))\n",
        "    sentimentVector.append(snt['neg'])\n",
        "    sentimentVector.append(snt['neu'])\n",
        "    sentimentVector.append(snt['pos'])\n",
        "    sentimentVector.append(snt['compound'])\n",
        "    \n",
        "    print(sentimentVector)\n",
        "    return sentimentVector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JL2RwuT4xvDa",
        "colab_type": "text"
      },
      "source": [
        "- senti.polarity_scores is a dictionary\n",
        "- pos and neg indicates - positive and negative emotions in sentence\n",
        "- we should be interested in compound score which calculates the final effect"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PN8fZ3rQxvDb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentiment = []\n",
        "vader_pol = []\n",
        "cmp_score = []\n",
        "for row in train_news['clean']:\n",
        "    get_pols = get_polarity_type(row)\n",
        "    sentiment.append(get_pols[1:])\n",
        "    vader_pol.append(get_pols[0])\n",
        "    cmp_score.append(get_pols[1:][-1]) #last element \n",
        "    \n",
        "train_news['sentiment_vector'] = sentiment\n",
        "train_news['vader_polarity'] = vader_pol\n",
        "train_news['sentiment_score'] = cmp_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "07Xld9ZqxvDc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_news.head(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzTH3t3bxvDe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentiment = []\n",
        "vader_pol = []\n",
        "cmp_score = []\n",
        "\n",
        "for row in test_news['clean']:\n",
        "    get_pols = get_polarity_type(row)\n",
        "    sentiment.append(get_pols[1:])\n",
        "    vader_pol.append(get_pols[0])\n",
        "    cmp_score.append(get_pols[1:][-1]) #last element \n",
        "    \n",
        "    \n",
        "test_news['sentiment_vector'] = sentiment\n",
        "test_news['vader_polarity'] = vader_pol\n",
        "test_news['sentiment_score'] = cmp_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "lzg1NAauxvDg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_news.head(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xI8el6U4xvDh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentiment = []\n",
        "vader_pol = []\n",
        "cmp_score = []\n",
        "\n",
        "for row in valid_news['clean']:\n",
        "    get_pols = get_polarity_type(row)\n",
        "    sentiment.append(get_pols[1:])\n",
        "    vader_pol.append(get_pols[0])\n",
        "    cmp_score.append(get_pols[1:][-1]) #last element \n",
        "    \n",
        "    \n",
        "valid_news['sentiment_vector'] = sentiment\n",
        "valid_news['vader_polarity'] = vader_pol\n",
        "valid_news['sentiment_score'] = cmp_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkZJV-exxvDj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "valid_news.head(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLOxOaEoxvDk",
        "colab_type": "text"
      },
      "source": [
        "##### Saved the trained dataset into a seperate CSV file "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XO7DqEyAxvDl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_news.to_csv(\"input_data/train_sentiment.csv\", sep=',')\n",
        "test_news.to_csv(\"input_data/test_sentiment.csv\", sep=',')\n",
        "valid_news.to_csv(\"input_data/valid_sentiment.csv\", sep=',')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjXNv_xAxvDo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import  LogisticRegression\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from nltk.stem.porter import *\n",
        "from sklearn import metrics\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "class SentimentAnalysis():\n",
        "\n",
        "    def __init__(self):        \n",
        "\n",
        "        columnNames = [\"jsonid\", \"label\", \"headline_text\", \"subject\", \"speaker\", \"speaker_job_title\", \"state_info\", \"party_affiliation\", \"barely_true_counts\", \"false_counts\", \"half_true_counts\", \"mostly_true_counts\", \"pants_on_fire_counts\", \"context\",\"clean\", \"sentiment_vector\",\"vader_polarity\", \"sentiment_score\"]\n",
        "        dataTrain = pd.read_csv('input_data/train_sentiment.csv', sep=',', header=None, names = columnNames)\n",
        "        dataTest = pd.read_csv('input_data/test_sentiment.csv', sep=',', header=None, names = columnNames)\n",
        "\n",
        "        #dropping columns\n",
        "        columnsToRemove = ['jsonid', 'label', 'subject', 'speaker','speaker_job_title', 'state_info', 'party_affiliation', 'barely_true_counts', 'false_counts', 'half_true_counts', 'mostly_true_counts', 'pants_on_fire_counts', 'context', 'sentiment_vector']\n",
        "        dataTrain = dataTrain.drop(columns=columnsToRemove)\n",
        "        dataTest = dataTest.drop(columns=columnsToRemove)\n",
        "        dataTrain = dataTrain.loc[1:] \n",
        "        dataTest = dataTest.loc[1:]\n",
        "    \n",
        "    \n",
        "        tfidfV = TfidfVectorizer(stop_words='english', min_df=5, max_df=30, use_idf=True, smooth_idf=True, token_pattern=u'(?ui)\\\\b\\\\w*[a-z]+\\\\w*\\\\b')\n",
        "\n",
        "        self.logR_pipeline = Pipeline([\n",
        "                ('LogRCV', tfidfV),\n",
        "                ('LogR_clf',LogisticRegression(solver='liblinear', C=32/100))\n",
        "                ])\n",
        "\n",
        "        self.logR_pipeline.fit(dataTrain['headline_text'],dataTrain['vader_polarity'])\n",
        "        predicted_LogR = self.logR_pipeline.predict(dataTest['headline_text'])\n",
        "        score = metrics.accuracy_score(dataTest['vader_polarity'], predicted_LogR)\n",
        "        print(\"Sentiment Analysis Model Trained - accuracy:   %0.6f\" % score)\n",
        "        \n",
        "\n",
        "    def predict(self, text):\n",
        "        predicted = self.logR_pipeline.predict([text])\n",
        "        predicedProb = self.logR_pipeline.predict_proba([text])[:,1]\n",
        "        return bool(predicted), float(predicedProb)\n",
        "    \n",
        "    \n",
        "sa = SentimentAnalysis()\n",
        "sa.predict(\"Says the Annies List political group supports third-trimester abortions on demand.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "VdNXPmIExvDq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SentimentAnalysis = SentimentAnalysis()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eH29vwZoxvDs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def DATAMINERS_getSentimentAnalysisScore(text):  # return between 0 and 1, being 0 = True,  1 = Fake\n",
        "    #print(clickBait.predict(\"Should You bring the money now\"))\n",
        "    binaryValue, probValue = SentimentAnalysis.predict(text)\n",
        "    return (float(probValue))\n",
        "\n",
        "print(DATAMINERS_getSentimentAnalysisScore(\"Says the Annies List political group supports third-trimester abortions on demand.\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2UibiXkxvDu",
        "colab_type": "text"
      },
      "source": [
        "# Feature 2:  LDA Topic Modelling \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJ3vIujlxvDu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_news['index'] = train_news.index\n",
        "data = train_news\n",
        "train_lda = data[['clean', 'index']]\n",
        "train_lda.head(4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ht1gLNYlxvDw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_news['index'] = test_news.index\n",
        "data = test_news\n",
        "test_lda = data[['clean', 'index']]\n",
        "test_lda.head(4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIMTNLRaxvDx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "valid_news['index'] = valid_news.index\n",
        "data = valid_news\n",
        "valid_lda = data[['clean', 'index']]\n",
        "valid_lda.head(4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-WoQlqDxvDz",
        "colab_type": "text"
      },
      "source": [
        "#### Split the clean news into list of words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXD1vOnmxvDz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "processed_docs = train_lda['clean'].map(lambda doc: doc.split(\" \"))\n",
        "processed_docs[:4]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4jGsl2SxvD1",
        "colab_type": "text"
      },
      "source": [
        "### Latent Dirichlet Allocation (LDA)\n",
        "\n",
        "> It is an example of a probabilistic topic model. Topic models are a great way to automatically explore and structure a large set of documents: they group or cluster documents based on the words that occur in them. As documents on similar topics tend to use a similar sub-vocabulary, the resulting clusters of documents can be interpreted as discussing different 'topics'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BeulswB7xvD1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_word_tokens(text):\n",
        "    result = []\n",
        "    for token in gensim.utils.simple_preprocess(text):\n",
        "        if len(token) > 3:\n",
        "            result.append(token)\n",
        "    return result\n",
        "tokenized_docs_local = train_news['clean'].map(get_word_tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lCsslHePxvD2",
        "colab_type": "text"
      },
      "source": [
        "### Create a function to build the dictionary and tokenized docs for given feature\n",
        "\n",
        "Below function does the following\n",
        "* #### Dictionary\n",
        "Returns Dictionary given, dataframe and column name\n",
        "* #### Tokenizeddocs\n",
        "Returns Tokenizeddocs, of the all the words in a text in that column can be used for bow_corpus\n",
        "* #### Dictionary is filtered using Gensim filter_extremes\n",
        "    Filter out tokens that appear in less than 15 documents (absolute number) or more than 0.5 documents (fraction of total corpus size, not absolute number). after the above two steps, keep only the first 100000 most frequent tokens.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJd77etqxvD3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_dictionary_print_words(dataframe,colname):\n",
        "    dictionary_gensim = gensim.corpora.Dictionary(processed_docs)\n",
        "    count = 0\n",
        "    print('######## DICTIONARY Words and occurences ########')\n",
        "    for k, v in dictionary_gensim.iteritems():\n",
        "        print(k, v)\n",
        "        count += 1\n",
        "        if count > 10:\n",
        "            break\n",
        "    dictionary_gensim.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)\n",
        "    return dictionary_gensim, tokenized_docs_local"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWzI-ZMDxvD4",
        "colab_type": "text"
      },
      "source": [
        "#### Gensim filter_extremes\n",
        "\n",
        "> Filter out tokens that appear less than 15 documents (absolute number) or more than 0.5 documents (fraction of total corpus size, not absolute number). after the above two steps, keep only the first 100000 most frequent tokens."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAxq-wlxxvD4",
        "colab_type": "text"
      },
      "source": [
        "#### Create a function to build bow_corpus from dictionary and tokenized_docs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzvYjbSRxvD5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_bow_corpus_print_sample(dataframe,colname):\n",
        "    dictionary_gensim, tokenized_docs_local = get_dictionary_print_words(dataframe, colname)\n",
        "    bow_corpus_local = [dictionary_gensim.doc2bow(doc) for doc in tokenized_docs_local]\n",
        "    bow_doc_local_0 = bow_corpus_local[0]\n",
        "    print('\\n ######## BOW VECTOR FIRST ITEM ########')\n",
        "    print(bow_doc_local_0)\n",
        "    print('\\n ######## PREVIEW BOW ########')\n",
        "    for i in range(len(bow_doc_local_0)):\n",
        "        print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_local_0[i][0], \n",
        "                                               dictionary_gensim[bow_doc_local_0[i][0]], bow_doc_local_0[i][1]))\n",
        "    return bow_corpus_local, dictionary_gensim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uX3t6U9qxvD7",
        "colab_type": "text"
      },
      "source": [
        "**Gensim doc2bow**\n",
        "\n",
        "For each document we create a dictionary reporting how many words and how many times those words appear. Save this to ‘bow_corpus’, then check our selected document earlier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ls5D4OH2xvD7",
        "colab_type": "text"
      },
      "source": [
        "#### Create a function to build tfidf_corpus from bow_corpus\n",
        "\n",
        "Create tf-idf model object using models.TfidfModel on ‘bow_corpus’ and save it to ‘tfidf’, then apply transformation to the entire corpus and call it ‘corpus_tfidf’. Finally we preview TF-IDF scores for our first document."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VOCreDIxvD7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_tfidf_corpus_print_sample(bow_corpus_local):\n",
        "    from gensim import corpora, models\n",
        "    tfidf = models.TfidfModel(bow_corpus_local)\n",
        "    tfidf_corpus_local = tfidf[bow_corpus_local]\n",
        "    print('\\n ######## TFIDF VECTOR FIRST ITEM ########')\n",
        "    \n",
        "    from pprint import pprint\n",
        "    for doc in tfidf_corpus_local:\n",
        "        pprint(doc)\n",
        "        break\n",
        "    return tfidf_corpus_local"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dB2I8ahRxvD9",
        "colab_type": "text"
      },
      "source": [
        "#### Create a function to run ldamodel and print top 10 topics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LH35gd1dxvD-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_lda_model_print_top_topics(bow_corpusforlda,numtopics,dictionaryforlda):\n",
        "    lda_model = gensim.models.LdaMulticore(bow_corpusforlda, num_topics=numtopics, id2word=dictionaryforlda, passes=2, workers=2)\n",
        "    lda_all_topics=lda_model.show_topics(num_topics=numtopics, num_words=10,formatted=False)\n",
        "    lda_topics_words = [(tp[0], [wd[0] for wd in tp[1]]) for tp in lda_all_topics]\n",
        "\n",
        "    #Below Code Prints Topics and Words\n",
        "    for topic,words in lda_topics_words:\n",
        "        print(str(topic)+ \"::\"+ str(words))\n",
        "    return lda_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNRPP03exvD_",
        "colab_type": "text"
      },
      "source": [
        "#### Create a function to run ldamodel and print top 10 topics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQz-vv8GxvD_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_lda_model_topics_topwords_print_top_topics(bow_corpusforlda,numtopics,dictionaryforlda):\n",
        "    lda_model = gensim.models.LdaMulticore(bow_corpusforlda, num_topics=numtopics, id2word=dictionaryforlda, passes=2, workers=2, random_state=1)\n",
        "    lda_all_topics=lda_model.show_topics(num_topics=numtopics, num_words=10,formatted=False)\n",
        "    lda_topics_words = [(tp[0], [wd[0] for wd in tp[1]]) for tp in lda_all_topics]\n",
        "\n",
        "    #Below Code Prints Topics and Words\n",
        "    for topic,words in lda_topics_words:\n",
        "        print(str(topic)+ \"::\"+ str(words))\n",
        "    return lda_model,lda_topics_words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XyegvlJAxvEC",
        "colab_type": "text"
      },
      "source": [
        "#### Create a function to enrich data with lda topics, lda topics score, top words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYQJyfh6xvEC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def identify_topic_number_score_label_topwords(text,dictionary_local,lda_model_local,lda_topics_top_words_local):\n",
        "    bow_vector_local = dictionary_local.doc2bow(get_word_tokens(text))\n",
        "    topic_number_local, topic_score_local = sorted(\n",
        "        lda_model_local[bow_vector_local], key=lambda tup: -1*tup[1])[0]\n",
        "    #print (topic_number_local, topic_score_local)\n",
        "    return pd.Series([topic_number_local, topic_score_local,\" \".join(lda_topics_top_words_local[int(topic_number_local)][1])])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0rQHqcPxvED",
        "colab_type": "text"
      },
      "source": [
        "#### Create a function that can enrich topic data to dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYLQ5_GPxvEE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def update_lda_results_to_dataset(dataframe,topiccolnames,coltoapplylda,colnamedictionary,colnameldamodel, colnameldatopwords):\n",
        "    dataframe[topiccolnames] = dataframe.apply(\n",
        "    lambda row: identify_topic_number_score_label_topwords(\n",
        "        row[coltoapplylda],colnamedictionary,colnameldamodel,\n",
        "        colnameldatopwords), axis=1)\n",
        "    return dataframe"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0o-sCgyhxvEF",
        "colab_type": "text"
      },
      "source": [
        "### Bag of Words\n",
        "\n",
        "#### Create a dictionary and tokens\n",
        "\n",
        "> Create a dictionary from ‘processed_docs’ containing the number of times a word appears in the training set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9tNn2SrxvEG",
        "colab_type": "text"
      },
      "source": [
        "#### Create a function to convert text to word tokens from cleaned dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTEW-5zOxvEH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bow_corpus_headline, dictionary_headline = get_bow_corpus_print_sample(train_news,\n",
        "                                                                      'clean')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ireF8K1sxvEI",
        "colab_type": "text"
      },
      "source": [
        "### Running LDA using Bag of Words\n",
        "Train our lda model using gensim.models.LdaMulticore and save it to ‘lda_model’"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2H32etwxvEI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lda_model_headline, lda_headline_topic_words = get_lda_model_topics_topwords_print_top_topics(\n",
        "    bow_corpus_headline, 10 ,dictionary_headline)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEMbf252xvEK",
        "colab_type": "text"
      },
      "source": [
        "#### Generate TF-IDF bow_corpus\n",
        "Create tf-idf model object using models.TfidfModel on ‘bow_corpus’ and save it to ‘tfidf’, then apply transformation to the entire corpus and call it ‘corpus_tfidf’. Finally we preview TF-IDF scores for our first document."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHWfghZ3xvEK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfidf_corpus_headline = get_tfidf_corpus_print_sample(bow_corpus_headline)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Zb41E_8xvEL",
        "colab_type": "text"
      },
      "source": [
        "### Running LDA model using Bag of Words\n",
        "Train our lda model using gensim.models.LdaMulticore and save it to ‘lda_model’\n",
        "\n",
        "**GOAL**: To get top ten topics with top words. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "s4ucB59qxvEM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lda_tfidf_model_headline  = get_lda_model_print_top_topics(tfidf_corpus_headline,10,dictionary_headline)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUwRvaVRxvEN",
        "colab_type": "text"
      },
      "source": [
        "#### Explanation for LDA \n",
        "![[Explanation of LDA](http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1508239587/n4ZpIXl_egq7mq.png)](http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1508239587/n4ZpIXl_egq7mq.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzZ1mRgRxvEO",
        "colab_type": "text"
      },
      "source": [
        "### Semisupervised Labeling\n",
        "Based on train,test and valid data explored the topic scores for sample data and identified below topics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OauFKyhuxvEO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "semisupervised_topic_labels = ['topic0','topic1','topic2','topic3','topic4','topic5','topic6','topic7','topic8','topic9']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CCFvz6MxvEP",
        "colab_type": "text"
      },
      "source": [
        "####  Function to add topicnumber, topicscore, topiclabel, topwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DymM1KRzxvEQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "headlinetopiccolnames = ['topic_number','lda_score','topic_top_words']\n",
        "train_news = update_lda_results_to_dataset(\n",
        "    train_news, headlinetopiccolnames,'clean', dictionary_headline, lda_model_headline, lda_headline_topic_words)\n",
        "train_news.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cO1i9zJyxvES",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_news = update_lda_results_to_dataset(\n",
        "    test_news,headlinetopiccolnames,'clean',\n",
        "  dictionary_headline,lda_model_headline,lda_headline_topic_words)\n",
        "test_news.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArEA_hPixvET",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "valid_news = update_lda_results_to_dataset(\n",
        "    valid_news,headlinetopiccolnames,'clean',\n",
        "  dictionary_headline,lda_model_headline,lda_headline_topic_words)\n",
        "valid_news.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5BPCW_8xvEU",
        "colab_type": "text"
      },
      "source": [
        "### Visualize the LDA Distribution of news against Top 10 Topics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aE2535txvEU",
        "colab_type": "text"
      },
      "source": [
        "**GOAL 1:** *Each of the N documents will be represented in the LDA model by a vector of length M*\n",
        "**GOAL 2:** *Each of the M topics is represented by a vector of length V*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABPG6u5AxvEW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import seaborn as sb\n",
        "def create_distribution(dataFile):\n",
        "    g = sb.countplot(x='topic_number', data=dataFile, palette='hls')\n",
        "    g.set_xticklabels(g.get_xticklabels(),rotation=90)\n",
        "\n",
        "    return g\n",
        "\n",
        "create_distribution(train_news) # TRAIN Document Vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "JZZBiUrPxvEX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "create_distribution(test_news)# TEST Document Vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "gilSA_6WxvEZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "create_distribution(valid_news)# VALID Document Vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5Lt8lFaxvEb",
        "colab_type": "text"
      },
      "source": [
        "##### Saved the latest dataset into a seperate CSV file "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIZdtOTHxvEc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_news.to_csv(\"input_data/train_lda.csv\", sep=',')\n",
        "test_news.to_csv(\"input_data/test_lda.csv\", sep=',')\n",
        "valid_news.to_csv(\"input_data/valid_lda.csv\", sep=',')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nYTtB4vxvEd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import  LogisticRegression\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from nltk.stem.porter import *\n",
        "from sklearn import metrics\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "class LDATopicModelling():\n",
        "\n",
        "    def __init__(self):        \n",
        "\n",
        "        columnNames = [\"jsonid\", \"label\", \"headline_text\", \"subject\", \"speaker\", \"speaker_job_title\", \"state_info\", \"party_affiliation\", \"barely_true_counts\", \"false_counts\", \"half_true_counts\", \"mostly_true_counts\", \"pants_on_fire_counts\", \"context\",\"clean\", \"sentiment_vector\",\"vader_polarity\", \"sentiment_score\", \"index\", \"topic_number\", \"lda_score\", \"topic_top_words\"]\n",
        "        dataTrain = pd.read_csv('input_data/train_lda.csv', sep=',', header=None, names = columnNames)\n",
        "        dataTest = pd.read_csv('input_data/test_lda.csv', sep=',', header=None, names = columnNames)\n",
        "\n",
        "        #dropping columns\n",
        "        columnsToRemove = ['jsonid', 'label', 'subject', 'speaker','speaker_job_title', 'state_info', 'party_affiliation', 'barely_true_counts', 'false_counts', 'half_true_counts', 'mostly_true_counts', 'pants_on_fire_counts', 'context', 'sentiment_vector', 'sentiment_vector','vader_polarity', 'sentiment_score', 'index']\n",
        "        dataTrain = dataTrain.drop(columns=columnsToRemove)\n",
        "        dataTest = dataTest.drop(columns=columnsToRemove)\n",
        "        dataTrain = dataTrain.loc[1:] \n",
        "        dataTest = dataTest.loc[1:]\n",
        "    \n",
        "    \n",
        "        tfidfV = TfidfVectorizer(stop_words='english', min_df=5, max_df=30, use_idf=True, smooth_idf=True, token_pattern=u'(?ui)\\\\b\\\\w*[a-z]+\\\\w*\\\\b')\n",
        "\n",
        "        self.logR_pipeline = Pipeline([\n",
        "                ('LogRCV', tfidfV),\n",
        "                ('LogR_clf',LogisticRegression(solver='liblinear', C=32/100))\n",
        "                ])\n",
        "\n",
        "        self.logR_pipeline.fit(dataTrain['headline_text'],dataTrain['topic_number'])\n",
        "        predicted_LogR = self.logR_pipeline.predict(dataTest['headline_text'])\n",
        "        score = metrics.accuracy_score(dataTest['topic_number'], predicted_LogR)\n",
        "        print(\"LDA Topic Model Trained - accuracy:   %0.6f\" % score)\n",
        "        \n",
        "\n",
        "    def predict(self, text):\n",
        "        predicted = self.logR_pipeline.predict([text])\n",
        "        predicedProb = self.logR_pipeline.predict_proba([text])[:,1]\n",
        "        return bool(predicted), float(predicedProb)\n",
        "    \n",
        "    \n",
        "# lda = LDATopicModelling()\n",
        "# lda.predict(\"Says the Annies List political group supports third-trimester abortions on demand.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "vPLf2TIsxvEf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ldaTopicModelling = LDATopicModelling()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-QKqXDaxvEh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def DATAMINERS_getLDATopicModellingScore(text):  # return between 0 and 1, being 0 = True,  1 = Fake\n",
        "    #print(clickBait.predict(\"Should You bring the money now\"))\n",
        "    binaryValue, probValue = ldaTopicModelling.predict(text)\n",
        "    return (float(probValue))\n",
        "\n",
        "print(DATAMINERS_getLDATopicModellingScore(\"Says the Annies List political group supports third-trimester abortions on demand.\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gm-pOW5vxvEi",
        "colab_type": "text"
      },
      "source": [
        "# Feature 3:  Sensational Feature Analysis\n",
        "\n",
        "#### [Sensational Words Corpus](https://www.thepersuasionrevolution.com/380-high-emotion-persuasive-words/)\n",
        "\n",
        ">  Words aren’t just strings of alphabets sewn together with ink. Words are cues. Words are triggers. Words when used correctly can transform an “eh whatever” into “wow that’s it!”. Words can make you go from literally ROFL to fuming with fury to an uncontrollable-urge-to-take-action-NOW-or-the-earth-may-stop-swinging -on-its-axis.\n",
        "\n",
        "> Highly emotional words are capable capable of transforming an absolute no into almost yes and a “perhaps” into “for sure”!\n",
        "\n",
        "Words that are used:\n",
        "- When you are trying to sell people a solution\n",
        "- When you are trying to get them to take an action (like, share, subscribe, buy)\n",
        "- When you are trying to get people to click and read your article\n",
        "- When you are trying to get someone to agree with you\n",
        "\n",
        "**There are 1400+ words that are both positive and negative emotions that will help to predict the sensational score for an article**\n",
        "\n",
        "> I have used these words to perform cosin similarity and predict the sensational similarity score for each news in the give dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_y2--MYxvEi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "columnNames = [\"jsonid\", \"label\", \"headline_text\", \"subject\", \"speaker\", \"speaker_job_title\", \"state_info\", \"party_affiliation\", \"barely_true_counts\", \"false_counts\", \"half_true_counts\", \"mostly_true_counts\", \"pants_on_fire_counts\", \"context\",\"clean\", \"sentiment_vector\",\"vader_polarity\", \"sentiment_score\", \"index\", \"topic_number\", \"lda_score\", \"topic_top_words\"]\n",
        "dataTrain = pd.read_csv('input_data/train_lda.csv', sep=',', header=None, names = columnNames)\n",
        "dataTest = pd.read_csv('input_data/test_lda.csv', sep=',', header=None, names = columnNames)\n",
        "\n",
        "#dropping columns\n",
        "columnsToRemove = ['jsonid', 'label', 'subject', 'speaker','speaker_job_title', 'state_info', 'party_affiliation', 'barely_true_counts', 'false_counts', 'half_true_counts', 'mostly_true_counts', 'pants_on_fire_counts', 'context', 'sentiment_vector', 'sentiment_vector','vader_polarity', 'sentiment_score', 'index', 'topic_number', 'lda_score', 'topic_top_words']\n",
        "train_news = dataTrain.drop(columns=columnsToRemove)\n",
        "test_news = dataTest.drop(columns=columnsToRemove)\n",
        "train_news = train_news.loc[1:] \n",
        "test_news = test_news.loc[1:]\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Q7AigHvxvEj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus = []\n",
        "for i in train_news['clean']:\n",
        "    corpus.append(i)\n",
        "# corpus\n",
        "\n",
        "sensational_corpus=[]\n",
        "sensational_words = pd.read_csv('input_data/sensationalism/sensational_words_dict.csv', sep=\"\\t+\", header=None, usecols=[0] )\n",
        "print(len(sensational_words))\n",
        "sensational_dictionary = ' '.join(sensational_words[0].astype(str))\n",
        "sensational_corpus.append(sensational_dictionary)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLipfgWdxvEm",
        "colab_type": "text"
      },
      "source": [
        "## SenticNet:   \n",
        "\n",
        "#### Data Enrichment \n",
        "\n",
        "> It provides polarity associated with 50,000 natural language concepts. A polarity is a floating number between -1 and +1. Minus one is extreme negativity, and plus one is extreme positivity. The knowledge base is free. It can be downloaded as XML file. \n",
        "SenticNet 5 reaches 100,000 commonsense concepts by employing recurrent neural networks to infer primitives by lexical substitution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "ftqq7AiHxvEm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import scale\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "sentic_net = pd.read_csv('input_data/sensationalism/senticnet5.txt', sep=\"\\t+\", header=None, usecols=[0,1,2], names = [\"Token\", \"Polarity\", \"Intensity\"])\n",
        "sentic_net = sentic_net[~sentic_net['Token'].str.contains('|'.join('_'),na=False)]\n",
        "sentic_net = sentic_net.reset_index(drop=True)\n",
        "print(\"Senticnet Vocab Size: \",len(sentic_net))\n",
        "print(sentic_net.head(10))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHC_XmsdxvEo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sentic_net['Token'] provides list of words from the SenticNet DICTIONARY\n",
        "senti_pos = sentic_net.loc[sentic_net.Polarity == \"positive\"]\n",
        "senti_pos = senti_pos.loc[senti_pos.Intensity > 0.90]\n",
        "dictionary = ' '.join(senti_pos.Token.astype(str))\n",
        "sensational_corpus.append(dictionary)\n",
        "print(len(senti_pos))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVV6-_x7xvEp",
        "colab_type": "text"
      },
      "source": [
        "## TF-IDF and Cosine Similarity\n",
        "\n",
        "#### TF-IDF\n",
        "\n",
        "> TF-IDF (Term Frequency - Inverse Document Frequency) can be represented tf(d,t) X idf(t). TF-IDF uses the method diminishing the weight (importance) of words appeared in many documents in common, considered them incapable of discerning the documents, rather than simply counting the frequency of words as CountVectorizer does. The outcome matrix consists of each document (row) and each word (column) and the importance (weight) computed by tf * idf (values of the matrix)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "io9qJY4kxvEp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidfVec = TfidfVectorizer(max_features=1000)\n",
        "\n",
        "tfidf_corpus = tfidfVec.fit_transform(corpus)\n",
        "tf_idf_senti = tfidfVec.fit_transform(sensational_corpus)\n",
        "words = tfidfVec.get_feature_names()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-g-XzzYGxvEq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfidf_corpus.toarray()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p80235r9xvEr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf_idf_senti.toarray()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHTgr3CMxvEt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfidfVec.vocabulary_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "zh3dhcjqxvEv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_tfidf = tfidfVec.fit_transform(train_news['clean'])\n",
        "print('Training dim:', train_tfidf.shape)\n",
        "print(train_tfidf.A[:10])\n",
        "\n",
        "\n",
        "test_tfidf = tfidfVec.fit_transform(test_news['clean'])\n",
        "print('Test dim:', test_tfidf.shape)\n",
        "print(test_tfidf.A[:10])\n",
        "\n",
        "\n",
        "# valid_tfidf = tfidfVec.fit_transform(valid_news['clean'])\n",
        "# print('Valid dim:', valid_tfidf.shape)\n",
        "# print(valid_tfidf.A[:10])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7VLPR_rxvEw",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "#### Cosine Similarity Score\n",
        "\n",
        "> The cosine similarity between two vectors (or two documents on the Vector Space) is a measure that calculates the cosine of the angle between them. This metric is a measurement of orientation and not magnitude, it can be seen as a comparison between documents on a normalized space because we’re not taking into the consideration only the magnitude of each word count (tf-idf) of each document, but the angle between the documents.\n",
        "\n",
        "> I have compared the sentiment vector of each doucment and estimated a similarity score which is saved as a column in the training and test dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dC_LtEZbxvEw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from sklearn.metrics.pairwise import cosine_similarity\n",
        "from scipy import spatial\n",
        "similarity_score = []\n",
        "for i in range(len(train_tfidf.toarray())):\n",
        "    similarity_score.append(1 - spatial.distance.cosine(tf_idf_senti[0].toarray(), tfidf_corpus[i].toarray()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "IWCIh-c8xvEy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_news['sensational_score'] = similarity_score\n",
        "train_news.head(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-CvVE1xxvEz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus = []\n",
        "for i in test_news['clean']:\n",
        "    corpus.append(i)\n",
        "# corpus\n",
        "\n",
        "tfidf_corpus = tfidfVec.fit_transform(corpus)\n",
        "\n",
        "similarity_score = []\n",
        "for i in range(len(test_tfidf.toarray())):\n",
        "    similarity_score.append(1 - spatial.distance.cosine(tf_idf_senti[0].toarray(), tfidf_corpus[i].toarray()))\n",
        "    \n",
        "test_news['sensational_score'] = similarity_score\n",
        "test_news.head(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4R5sEdeuxvE1",
        "colab_type": "text"
      },
      "source": [
        "##### Saved the latest dataset into a seperate CSV file "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMP25qo8xvE1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_news.to_csv(\"input_data/train_sensationalism.csv\", sep=',')\n",
        "test_news.to_csv(\"input_data/test_sensationalism.csv\", sep=',')\n",
        "valid_news.to_csv(\"input_data/valid_sensationalism.csv\", sep=',')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsWzs62-xvE2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "columnNames = [\"jsonid\", \"headline_text\", \"clean\", \"sensational_score\"]\n",
        "dataTrain = pd.read_csv('input_data/train_sensationalism.csv', sep=',', header=None, names = columnNames)\n",
        "dataTest = pd.read_csv('input_data/test_sensationalism.csv', sep=',', header=None, names = columnNames)\n",
        "\n",
        "dataTrain = dataTrain.loc[1:]\n",
        "dataTest = dataTest.loc[1:]\n",
        "\n",
        "\n",
        "dataTrain.head(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPa8Rlm-xvE5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import  LogisticRegression\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from nltk.stem.porter import *\n",
        "from sklearn import metrics\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from sklearn.preprocessing import Imputer\n",
        "\n",
        "\n",
        "class SensationalismFeature():\n",
        "\n",
        "    def __init__(self):        \n",
        "\n",
        "        columnNames = [\"jsonid\", \"headline_text\", \"clean\", \"sensational_score\"]\n",
        "        dataTrain = pd.read_csv('input_data/train_sensationalism.csv', sep=',', header=None, names = columnNames)\n",
        "        dataTest = pd.read_csv('input_data/test_sensationalism.csv', sep=',', header=None, names = columnNames)\n",
        "        dataTrain = dataTrain.loc[1:]\n",
        "        dataTest = dataTest.loc[1:]\n",
        "            \n",
        "        tfidfV = TfidfVectorizer(stop_words='english', min_df=5, max_df = 30, use_idf = True, smooth_idf = True, token_pattern=u'(?ui)\\\\b\\\\w*[a-z]+\\\\w*\\\\b')\n",
        "\n",
        "        self.logR_pipeline = Pipeline([\n",
        "                ('LogRCV', tfidfV),\n",
        "                ('LogR_clf', LogisticRegression(solver='liblinear', C = 32/100))\n",
        "                ])\n",
        "\n",
        "        self.logR_pipeline.fit(dataTrain['headline_text'], dataTrain['sensational_score'].astype(str))\n",
        "        predicted_LogR = self.logR_pipeline.predict(dataTest['headline_text'])\n",
        "        score = metrics.accuracy_score(dataTest['sensational_score'].astype(str), predicted_LogR)\n",
        "        print(\"Sensationalism Model Trained - accuracy:   %0.6f\" % score)\n",
        "        \n",
        "\n",
        "    def predict(self, text):\n",
        "        predicted = self.logR_pipeline.predict([text])\n",
        "        predicedProb = self.logR_pipeline.predict_proba([text])[:,1]\n",
        "        return bool(predicted), float(predicedProb)\n",
        "    \n",
        "    \n",
        "sf = SensationalismFeature()\n",
        "# sf.predict(\"Says the Annies List political group supports third-trimester abortions on demand.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQhty4wTxvE6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def DATAMINERS_getSensationalismScore(text):  # return between 0 and 1, being 0 = True,  1 = Fake\n",
        "    #print(clickBait.predict(\"Should You bring the money now\"))\n",
        "    binaryValue, probValue = sf.predict(text)\n",
        "    return (float(probValue*100))\n",
        "\n",
        "print(DATAMINERS_getSensationalismScore(\"Says the Annies List political group supports third-trimester abortions on demand.\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9L5vxKaxvE7",
        "colab_type": "text"
      },
      "source": [
        "# Feature 4: Political Affiliation Model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "MkKrLwqHxvE7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import  LogisticRegression\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from nltk.stem.porter import *\n",
        "from sklearn import metrics\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import  LogisticRegression\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn import svm\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "#from sklearn.cross_validation import KFold\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import confusion_matrix, f1_score, classification_report\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import learning_curve\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import average_precision_score\n",
        "import matplotlib.pyplot as plt\n",
        "import itertools\n",
        "\n",
        "class PartyAffiliation():\n",
        "    \n",
        "    # API to check whether the subject(Headline) is present in the \n",
        "    # - democrats most used words if the party affiliation is democrat\n",
        "    # - republicans most used words if the part affiliation is republican\n",
        "    def partyAffiliationFromHeadline(self, r):\n",
        "        v = r['subject_str']\n",
        "        p = r['party_str']\n",
        "        if (p =='democrat'):\n",
        "            s2 = set(self.countDemV.get_feature_names())\n",
        "        if (p =='republican'):\n",
        "            s2 = set(self.countRepV.get_feature_names())\n",
        "        if (p != 'democract' and p !='republican'):\n",
        "            return 1 #'true'        \n",
        "        if set(v).intersection(s2):\n",
        "            return 1 #'true'\n",
        "        else:\n",
        "            return 0 #'false'\n",
        "\n",
        "    #API to convert true, mostly-true and half-true to true\n",
        "    # false, barely-true and pants-fire to false\n",
        "    def convertMulticlassToBinaryclass(self, r):\n",
        "        v = r['label']\n",
        "        if (v == 'true'):\n",
        "            return 1 #'true'\n",
        "        if (v == 'mostly-true'):\n",
        "            return 1 #'true'\n",
        "        if (v == 'half-true'):\n",
        "            return 1 #'true'\n",
        "        if (v == 'barely-true'):\n",
        "            return 0 #'false'\n",
        "        if (v == 'false'):\n",
        "            return 0 #'false'\n",
        "        if (v == 'pants-fire'):\n",
        "            return 0 #'false'\n",
        "            \n",
        "            \n",
        "            \n",
        "    def plot_confusion_matrix(self, cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
        "\n",
        "        plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "        plt.title(title)\n",
        "        plt.colorbar()\n",
        "        tick_marks = np.arange(len(classes))\n",
        "        plt.xticks(tick_marks, classes, rotation=45)\n",
        "        plt.yticks(tick_marks, classes)\n",
        "\n",
        "        if normalize:\n",
        "            cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "            print(\"Normalized confusion matrix\")\n",
        "        else:\n",
        "            print('Confusion matrix, without normalization')\n",
        "\n",
        "        thresh = cm.max() / 2.\n",
        "        for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "            plt.text(j, i, cm[i, j],\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.ylabel('True label')\n",
        "        plt.xlabel('Predicted label')       \n",
        "            \n",
        "    \n",
        "    def __init__(self):        \n",
        "\n",
        "        columnNamesPar = [\"id\", \"label\", \"statement\", \"subject\", \"speaker\", \"speaker_job_title\", \"state_info\", \"party_affiliation\", \"barely_true_counts\", \"false_counts\", \"half_true_counts\", \"mostly_true_counts\", \"pants_on_fire_counts\", \"context\"]\n",
        "        dataTrainPar = pd.read_csv('input_data/dataset/train.tsv', sep='\\t', header=None, names = columnNamesPar)\n",
        "        dataValidatePar = pd.read_csv('input_data/dataset/valid.tsv', sep='\\t', header=None, names = columnNamesPar)\n",
        "        dataTestPar = pd.read_csv('input_data/dataset/test.tsv', sep='\\t', header=None, names = columnNamesPar)\n",
        "        \n",
        "    \n",
        "        # Remove unwanted columns in the dataset\n",
        "        columnsToRemovePar = ['id', 'speaker', 'context','speaker_job_title', 'barely_true_counts', 'false_counts', 'half_true_counts', 'mostly_true_counts', 'pants_on_fire_counts']\n",
        "        dataTrainPar = dataTrainPar.drop(columns=columnsToRemovePar)\n",
        "        dataValidatePar = dataValidatePar.drop(columns=columnsToRemovePar)\n",
        "        dataTestPar = dataTestPar.drop(columns=columnsToRemovePar)\n",
        "        \n",
        "        # convert the labels to true and false only\n",
        "        dataTrainPar['label'] = dataTrainPar.apply(self.convertMulticlassToBinaryclass, axis=1)\n",
        "        dataValidatePar['label'] = dataValidatePar.apply(self.convertMulticlassToBinaryclass, axis=1)\n",
        "        dataTestPar['label'] = dataTestPar.apply(self.convertMulticlassToBinaryclass, axis=1)\n",
        "        \n",
        "        # display all the party affiliations and show the count of each party \n",
        "#         dataTrainPar.groupby('party_affiliation').count()[['state_info']].rename(\n",
        "#         columns={'state_info': 'count'}).sort_values(\n",
        "#         'count', ascending=False).reset_index().plot.bar(\n",
        "#         x='party_affiliation', y='count', figsize=(16, 10), fontsize=18);\n",
        "        \n",
        "        # As we are considering only democrat, republican and none (top 3 party affiliations),\n",
        "        # ignoring other party affiliations\n",
        "        rowsToRemove = ['Moderate', 'activist', 'business-leader', 'columnist', 'constitution-party', 'democratic-farmer-labor', 'education-official', 'government-body', 'green', 'independent', 'journalist', 'labor-leader', 'liberal-party-canada', 'libertarian', 'nan', 'newsmaker', 'ocean-state-tea-party-action', 'organization', 'state-official', 'talk-show-host', 'tea-party-member']\n",
        "\n",
        "        dataTrainPar = dataTrainPar[dataTrainPar.party_affiliation != 'Moderate']\n",
        "        dataTrainPar = dataTrainPar[dataTrainPar.party_affiliation != 'activist']\n",
        "        dataTrainPar = dataTrainPar[dataTrainPar.party_affiliation != 'business-leader']\n",
        "        dataTrainPar = dataTrainPar[dataTrainPar.party_affiliation != 'columnist']\n",
        "        dataTrainPar = dataTrainPar[dataTrainPar.party_affiliation != 'constitution-party']\n",
        "        dataTrainPar = dataTrainPar[dataTrainPar.party_affiliation != 'democratic-farmer-labor']\n",
        "        dataTrainPar = dataTrainPar[dataTrainPar.party_affiliation != 'education-official']\n",
        "        dataTrainPar = dataTrainPar[dataTrainPar.party_affiliation != 'government-body']\n",
        "        dataTrainPar = dataTrainPar[dataTrainPar.party_affiliation != 'green']\n",
        "        dataTrainPar = dataTrainPar[dataTrainPar.party_affiliation != 'independent']\n",
        "        dataTrainPar = dataTrainPar[dataTrainPar.party_affiliation != 'journalist']\n",
        "        dataTrainPar = dataTrainPar[dataTrainPar.party_affiliation != 'labor-leader']\n",
        "        dataTrainPar = dataTrainPar[dataTrainPar.party_affiliation != 'liberal-party-canada']\n",
        "        dataTrainPar = dataTrainPar[dataTrainPar.party_affiliation != 'libertarian']\n",
        "        dataTrainPar = dataTrainPar[dataTrainPar.party_affiliation != 'nan']\n",
        "        dataTrainPar = dataTrainPar[dataTrainPar.party_affiliation != 'newsmaker']\n",
        "        dataTrainPar = dataTrainPar[dataTrainPar.party_affiliation != 'ocean-state-tea-party-action']\n",
        "        dataTrainPar = dataTrainPar[dataTrainPar.party_affiliation != 'organization']\n",
        "        dataTrainPar = dataTrainPar[dataTrainPar.party_affiliation != 'state-official']\n",
        "        dataTrainPar = dataTrainPar[dataTrainPar.party_affiliation != 'talk-show-host']\n",
        "        dataTrainPar = dataTrainPar[dataTrainPar.party_affiliation != 'tea-party-member']\n",
        "\n",
        "        # As we are considering only democrat, republican and none (top 3 party affiliations),\n",
        "        # ignoring other party affiliations\n",
        "\n",
        "        dataTestPar = dataTestPar[dataTestPar.party_affiliation != 'Moderate']\n",
        "        dataTestPar = dataTestPar[dataTestPar.party_affiliation != 'activist']\n",
        "        dataTestPar = dataTestPar[dataTestPar.party_affiliation != 'business-leader']\n",
        "        dataTestPar = dataTestPar[dataTestPar.party_affiliation != 'columnist']\n",
        "        dataTestPar = dataTestPar[dataTestPar.party_affiliation != 'constitution-party']\n",
        "        dataTestPar = dataTestPar[dataTestPar.party_affiliation != 'democratic-farmer-labor']\n",
        "        dataTestPar = dataTestPar[dataTestPar.party_affiliation != 'education-official']\n",
        "        dataTestPar = dataTestPar[dataTestPar.party_affiliation != 'government-body']\n",
        "        dataTestPar = dataTestPar[dataTestPar.party_affiliation != 'green']\n",
        "        dataTestPar = dataTestPar[dataTestPar.party_affiliation != 'independent']\n",
        "        dataTestPar = dataTestPar[dataTestPar.party_affiliation != 'journalist']\n",
        "        dataTestPar = dataTestPar[dataTestPar.party_affiliation != 'labor-leader']\n",
        "        dataTestPar = dataTestPar[dataTestPar.party_affiliation != 'liberal-party-canada']\n",
        "        dataTestPar = dataTestPar[dataTestPar.party_affiliation != 'libertarian']\n",
        "        dataTestPar = dataTestPar[dataTestPar.party_affiliation != 'nan']\n",
        "        dataTestPar = dataTestPar[dataTestPar.party_affiliation != 'newsmaker']\n",
        "        dataTestPar = dataTestPar[dataTestPar.party_affiliation != 'ocean-state-tea-party-action']\n",
        "        dataTestPar = dataTestPar[dataTestPar.party_affiliation != 'organization']\n",
        "        dataTestPar = dataTestPar[dataTestPar.party_affiliation != 'state-official']\n",
        "        dataTestPar = dataTestPar[dataTestPar.party_affiliation != 'talk-show-host']\n",
        "        dataTestPar = dataTestPar[dataTestPar.party_affiliation != 'tea-party-member']\n",
        "\n",
        "        \n",
        "        dataTrainPar['party_str'] = dataTrainPar['party_affiliation'].astype(str)\n",
        "        dataTestPar['party_str'] = dataTestPar['party_affiliation'].astype(str)\n",
        "        \n",
        "\n",
        "        #predicting truth level\n",
        "#        dataTrainPar.groupby('label').count()[['party_affiliation']].reset_index().plot.bar(x='label', y='party_affiliation')\n",
        "        \n",
        "        # get the most used democrat words\n",
        "        self.countDemV = CountVectorizer(stop_words='english', min_df=40, max_df=80, token_pattern=u'(?ui)\\\\b\\\\w*[a-z]+\\\\w*\\\\b')\n",
        "\n",
        "        dataTrainDem= dataTrainPar\n",
        "        dataTrainDem = dataTrainPar.loc[dataTrainPar['party_str'] == 'democrat']\n",
        "        dem_count = self.countDemV.fit_transform(dataTrainDem['statement'].values)\n",
        "        \n",
        "        #get the republican most used words\n",
        "        \n",
        "        self.countRepV = CountVectorizer(stop_words='english', min_df=20, max_df=40, token_pattern=u'(?ui)\\\\b\\\\w*[a-z]+\\\\w*\\\\b')\n",
        "        dataTrainRep= dataTrainPar\n",
        "        dataTrainRep = dataTrainPar.loc[dataTrainPar['party_str'] == 'republican']\n",
        "        rep_count = self.countRepV.fit_transform(dataTrainRep['statement'].values)\n",
        "\n",
        "        dataTestDem= dataTestPar\n",
        "        dataTestDem = dataTestPar.loc[dataTestPar['party_str'] == 'democrat']\n",
        "        \n",
        "        dataTrainPar['subject_str'] = dataTrainPar['subject'].astype(str).str.split() \n",
        "        dataTrainPar['label_str'] = dataTrainPar.apply(self.partyAffiliationFromHeadline, axis=1)\n",
        "\n",
        "        dataTestPar['subject_str'] = dataTestPar['subject'].astype(str).str.split() \n",
        "        dataTestPar['label_str'] = dataTestPar.apply(self.partyAffiliationFromHeadline, axis=1)\n",
        "\n",
        "        dataTrainDem['subject_str'] = dataTrainDem['subject'].astype(str).str.split() \n",
        "        dataTrainDem['label_str'] = dataTrainDem.apply(self.partyAffiliationFromHeadline, axis=1)\n",
        "    \n",
        "        dataTestDem['subject_str'] = dataTestDem['subject'].astype(str).str.split() \n",
        "        dataTestDem['label_str'] = dataTestDem.apply(self.partyAffiliationFromHeadline, axis=1)\n",
        "        \n",
        "        \n",
        "        self.model = LogisticRegression()\n",
        "        self.model = self.model.fit(dataTrainPar['label_str'].values.reshape(-1, 1), dataTrainPar['label'].values)\n",
        "        predicted_LogR = self.model.predict(dataTestPar['label_str'].values.reshape(-1, 1))\n",
        "        score = metrics.accuracy_score(dataTestPar['label'], predicted_LogR)\n",
        "        print(\"Party Affiliation Model Trained - accuracy:   %0.6f\" % score)\n",
        "\n",
        "    \n",
        "    def predict(self, headline, party):\n",
        "                \n",
        "        #creating the dataframe with our text so we can leverage the existing code\n",
        "        dfrme = pd.DataFrame(index=[0], columns=['subject', 'party_str'])\n",
        "        dfrme['subject_str'] = headline\n",
        "        dfrme['party_str'] = party        \n",
        "\n",
        "        dfrme['subject'] = headline\n",
        "        dfrme['subject_str'] = dfrme['subject'].astype(str).str.split() \n",
        "        dfrme['label_str'] = dfrme.apply(self.partyAffiliationFromHeadline, axis=1)\n",
        "        \n",
        "        x = dfrme['label_str'].values.reshape(-1, 1)\n",
        "        predicted = self.model.predict(x)\n",
        "        predicedProb = self.model.predict_proba(x)[:,1]\n",
        "        return predicted, predicedProb\n",
        "                    \n",
        "    \n",
        "##testing code\n",
        "f = PartyAffiliation()\n",
        "#pf.predict(\"Says the Annies List political group supports third-trimester abortions on demand\", \"republican\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "5RM4EWyOxvE8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from sklearn.exceptions import DataConversionWarning\n",
        "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def loadJsonFiles(directory, veracity):    \n",
        "    shouldAppend = False\n",
        "    for filename in os.listdir(directory):\n",
        "        df2 = pd.read_json(directory + filename, lines=True)\n",
        "        if (shouldAppend):\n",
        "            df = df.append(df2, ignore_index=True, sort=True)      \n",
        "        else:\n",
        "            df = df2\n",
        "        df['veracity'] = veracity\n",
        "        shouldAppend = True\n",
        "        \n",
        "            \n",
        "    # removing nan values    \n",
        "    df['source'].fillna(\"\", inplace=True)\n",
        "    for index, row in df.iterrows():\n",
        "        if (type(row['authors']) == float):\n",
        "            df.at[index, 'authors'] = []\n",
        "\n",
        "            \n",
        "    #removing unnecessary columns\n",
        "    df = df.drop(columns=['keywords','meta_data','movies', 'keywords', 'summary', 'publish_date','top_img'])\n",
        "    return df\n",
        "\n",
        "def loadDataset():\n",
        "    dataFake = loadJsonFiles('input_data/politifact/FakeNewsContent/', 0)\n",
        "    dataReal = loadJsonFiles('input_data/politifact/RealNewsContent/', 1)\n",
        "    return dataReal, dataFake\n",
        "\n",
        "dataFake, dataReal = loadDataset()\n",
        "\n",
        "dataTrainFake = dataFake[:100]\n",
        "dataTrainReal = dataReal[:100]\n",
        "dataTestFake = dataFake[101:]\n",
        "dataTestReal = dataReal[101:]\n",
        "\n",
        "dataTest = dataTestFake.append(dataTestReal,ignore_index=True, sort=True)      \n",
        "dataTrain = dataTrainFake.append(dataTrainReal,ignore_index=True, sort=True)    \n",
        "dataAll = dataFake.append(dataReal, ignore_index=True, sort=True)      \n",
        "dataAll.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "QrdqyKlbxvE9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from ipynb.fs.full.m_partyaffiliation import PartyAffiliation\n",
        "partyAffiliation = PartyAffiliation()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qb3-DUkQxvE-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def DATAMINERS_getPartyAffiliationScore(headline, partyName): # return between 0 and 1, being 0 = True,  1 = Fake\n",
        "    if ( (headline == \"\") | (partyName == \"\") ):\n",
        "        return 0\n",
        "    binaryValue, probValue = partyAffiliation.predict(headline, partyName)\n",
        "    return (1 - float(probValue))\n",
        "\n",
        "print(DATAMINERS_getPartyAffiliationScore(\"Says the Annies List political group supports third-trimester abortions on demand\", \"republican\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81NutCZIxvE_",
        "colab_type": "text"
      },
      "source": [
        "# Feature 5: Click Bait "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rui3oDmoxvFA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Clickbait():\n",
        "    \n",
        "    question_words = ['who', 'whos', 'whose', 'what', 'whats', 'whatre', 'when', 'whenre', 'whens', 'couldnt',\n",
        "            'where', 'wheres', 'whered', 'why', 'whys', 'can', 'cant', 'could', 'will', 'would', 'is',\n",
        "            'isnt', 'should', 'shouldnt', 'you', 'your', 'youre', 'youll', 'youd', 'here', 'heres',\n",
        "            'how', 'hows', 'howd', 'this', 'are', 'arent', 'which', 'does', 'doesnt']\n",
        "\n",
        "    contractions = ['tis', 'aint', 'amnt', 'arent', 'cant', 'couldve', 'couldnt', 'couldntve',\n",
        "                    'didnt', 'doesnt', 'dont', 'gonna', 'gotta', 'hadnt', 'hadntve', 'hasnt',\n",
        "                    'havent', 'hed', 'hednt', 'hedve', 'hell', 'hes', 'hesnt', 'howd', 'howll',\n",
        "                    'hows', 'id', 'idnt', 'idntve', 'idve', 'ill', 'im', 'ive', 'ivent', 'isnt',\n",
        "                    'itd', 'itdnt', 'itdntve', 'itdve', 'itll', 'its', 'itsnt', 'mightnt',\n",
        "                    'mightve', 'mustnt', 'mustntve', 'mustve', 'neednt', 'oclock', 'ol', 'oughtnt',\n",
        "                    'shant', 'shed', 'shednt', 'shedntve', 'shedve', 'shell', 'shes', 'shouldve',\n",
        "                    'shouldnt', 'shouldntve', 'somebodydve', 'somebodydntve', 'somebodys',\n",
        "                    'someoned', 'someonednt', 'someonedntve', 'someonedve', 'someonell', 'someones',\n",
        "                    'somethingd', 'somethingdnt', 'somethingdntve', 'somethingdve', 'somethingll',\n",
        "                    'somethings', 'thatll', 'thats', 'thatd', 'thered', 'therednt', 'theredntve',\n",
        "                    'theredve', 'therere', 'theres', 'theyd', 'theydnt', 'theydntve', 'theydve',\n",
        "                    'theydvent', 'theyll', 'theyontve', 'theyre', 'theyve', 'theyvent', 'wasnt',\n",
        "                    'wed', 'wedve', 'wednt', 'wedntve', 'well', 'wontve', 'were', 'weve', 'werent',\n",
        "                    'whatd', 'whatll', 'whatre', 'whats', 'whatve', 'whens', 'whered', 'wheres',\n",
        "                    'whereve', 'whod', 'whodve', 'wholl', 'whore', 'whos', 'whove', 'whyd', 'whyre',\n",
        "                    'whys', 'wont', 'wontve', 'wouldve', 'wouldnt', 'wouldntve', 'yall', 'yalldve',\n",
        "                    'yalldntve', 'yallll', 'yallont', 'yallllve', 'yallre', 'yallllvent', 'yaint',\n",
        "                    'youd', 'youdve', 'youll', 'youre', 'yourent', 'youve', 'youvent']\n",
        "    \n",
        "    def process_text(self, text):\n",
        "        result = text.replace('/', '').replace('\\n', '')\n",
        "        result = re.sub(r'[1-9]+', 'number', result)\n",
        "        result = re.sub(r'(\\w)(\\1{2,})', r'\\1', result)\n",
        "        result = re.sub(r'(?x)\\b(?=\\w*\\d)\\w+\\s*', '', result)\n",
        "        result = ''.join(t for t in result if t not in punctuation)\n",
        "        result = re.sub(r' +', ' ', result).lower().strip()\n",
        "        return result\n",
        "    \n",
        "    def cnt_stop_words(self, text):\n",
        "        s = text.split()\n",
        "        num = len([word for word in s if word in self.stop])\n",
        "        return num\n",
        "\n",
        "    def num_contract(self, text):\n",
        "        s = text.split()\n",
        "        num = len([word for word in s if word in self.contractions])\n",
        "        return num\n",
        "\n",
        "    def question_word(self, text):\n",
        "        s = text.split()\n",
        "        if s[0] in self.question_words:\n",
        "            return 1\n",
        "        else:\n",
        "            return 0\n",
        "\n",
        "    def part_of_speech(self, text):\n",
        "        s = text.split()\n",
        "        nonstop = [word for word in s if word not in self.stop]\n",
        "        pos = [part[1] for part in nltk.pos_tag(nonstop)]\n",
        "        pos = ' '.join(pos)\n",
        "        return pos\n",
        "\n",
        "\n",
        "    def __init__(self):        \n",
        "        df_ycb = pd.read_csv('input_data/clickbait/clickbait_data.txt', sep=\"\\n\", header=None, names=['text'])\n",
        "        df_ycb['clickbait'] = 1\n",
        "\n",
        "        df_ncb = pd.read_csv('input_data/clickbait/non_clickbait_data.txt', sep=\"\\n\", header=None, names=['text'])\n",
        "        df_ncb['clickbait'] = 0\n",
        "\n",
        "        df = df_ycb.append(df_ncb, ignore_index=True).reset_index(drop=True)\n",
        "\n",
        "        \n",
        "\n",
        "       \n",
        "        self.stop = stopwords.words('english')\n",
        "       \n",
        "        # Creating some latent variables from the data\n",
        "        df['text']     = df['text'].apply(self.process_text)\n",
        "        df['question'] = df['text'].apply(self.question_word)\n",
        "\n",
        "        df['num_words']       = df['text'].apply(lambda x: len(x.split()))\n",
        "        df['part_speech']     = df['text'].apply(self.part_of_speech)\n",
        "        df['num_contract']    = df['text'].apply(self.num_contract)\n",
        "        df['num_stop_words']  = df['text'].apply(self.cnt_stop_words)\n",
        "        df['stop_word_ratio'] = df['num_stop_words']/df['num_words']\n",
        "        df['contract_ratio']  = df['num_contract']/df['num_words']\n",
        "\n",
        "        \n",
        "        df.drop(['num_stop_words','num_contract'], axis=1, inplace=True)\n",
        "\n",
        "        df_train, df_test = train_test_split(df, test_size=0.2, random_state=0)\n",
        "\n",
        "        self.tfidf = TfidfVectorizer(min_df=3, max_features=None, strip_accents='unicode',\n",
        "                                   analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(1,5),\n",
        "                                   use_idf=1, smooth_idf=1, sublinear_tf=1)\n",
        "\n",
        "        X_train_text = self.tfidf.fit_transform(df_train['text'])\n",
        "        X_test_text  = self.tfidf.transform(df_test['text'])\n",
        "\n",
        "        self.cvec = CountVectorizer()\n",
        "\n",
        "        X_train_pos = self.cvec.fit_transform(df_train['part_speech'])\n",
        "        X_test_pos  = self.cvec.transform(df_test['part_speech'])\n",
        "\n",
        "        self.scNoMean = StandardScaler(with_mean=False)  # we pass with_mean=False to preserve the sparse matrix\n",
        "        X_train_pos_sc = self.scNoMean.fit_transform(X_train_pos)\n",
        "        X_test_pos_sc  = self.scNoMean.transform(X_test_pos)\n",
        "\n",
        "        X_train_val = df_train.drop(['clickbait','text','part_speech'], axis=1).values\n",
        "        X_test_val  = df_test.drop(['clickbait','text','part_speech'], axis=1).values\n",
        "\n",
        "        self.sc = StandardScaler()\n",
        "        X_train_val_sc = self.sc.fit(X_train_val).transform(X_train_val)\n",
        "        X_test_val_sc  = self.sc.transform(X_test_val)\n",
        "\n",
        "        y_train = df_train['clickbait'].values\n",
        "        y_test  = df_test['clickbait'].values\n",
        "\n",
        "\n",
        "\n",
        "        X_train = sparse.hstack([X_train_val_sc, X_train_text, X_train_pos_sc]).tocsr()\n",
        "        X_test  = sparse.hstack([X_test_val_sc, X_test_text, X_test_pos_sc]).tocsr()\n",
        "\n",
        "        self.model = LogisticRegression(penalty='l2', C=98.94736842105263)\n",
        "        self.model = self.model.fit(X_train, y_train)\n",
        "        \n",
        "        predicted_LogR = self.model.predict(X_test)\n",
        "        score = metrics.accuracy_score(y_test, predicted_LogR)\n",
        "        print(\"Clickbait Model Trained - accuracy:   %0.6f\" % score)\n",
        "\n",
        "#     predict = model.predict(X_test)\n",
        "#     print(classification_report(y_test, predict))\n",
        "\n",
        "\n",
        "    def predict(self, text):\n",
        "        #creating the dataframe with our text so we can leverage the existing code\n",
        "        dfrme = pd.DataFrame(index=[0], columns=['text'])\n",
        "        dfrme['text'] = text\n",
        "\n",
        "        #processing text\n",
        "        dfrme['text']     = dfrme['text'].apply(self.process_text)\n",
        "\n",
        "        #adding latent variables\n",
        "        dfrme['question'] = dfrme['text'].apply(self.question_word)\n",
        "        dfrme['num_words']       = dfrme['text'].apply(lambda x: len(x.split()))\n",
        "        dfrme['part_speech']     = dfrme['text'].apply(self.part_of_speech)\n",
        "        dfrme['num_contract']    = dfrme['text'].apply(self.num_contract)\n",
        "        dfrme['num_stop_words']  = dfrme['text'].apply(self.cnt_stop_words)\n",
        "        dfrme['stop_word_ratio'] = dfrme['num_stop_words']/dfrme['num_words']\n",
        "        dfrme['contract_ratio']  = dfrme['num_contract']/dfrme['num_words']\n",
        "\n",
        "        #removing latent variables that have high colinearity with other features\n",
        "        dfrme.drop(['num_stop_words','num_contract'], axis=1, inplace=True)\n",
        "\n",
        "\n",
        "        Xtxt_val  = dfrme.drop(['text','part_speech'], axis=1).values\n",
        "        Xtxt_val_sc  = self.sc.transform(Xtxt_val)\n",
        "\n",
        "        Xtxt_text  = self.tfidf.transform(dfrme['text'])\n",
        "\n",
        "        Xtxt_pos  = self.cvec.transform(dfrme['part_speech'])\n",
        "        Xtxt_pos_sc  = self.scNoMean.transform(Xtxt_pos)\n",
        "        Xtxt  = sparse.hstack([Xtxt_val_sc, Xtxt_text, Xtxt_pos_sc]).tocsr()\n",
        "\n",
        "        predicted = self.model.predict(Xtxt)\n",
        "        predicedProb = self.model.predict_proba(Xtxt)[:,1]\n",
        "        return predicted, predicedProb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "i-RofIcTxvFA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from ipynb.fs.full.m_clickbait import Clickbait\n",
        "clickBait = Clickbait()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bzh0lNPSxvFC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def DATAMINERS_getClickbaitScore(headline): # return between 0 and 1, being 0 = True,  1 = Fake\n",
        "    if (headline == \"\"):\n",
        "        return 0\n",
        "    binaryValue, probValue = clickBait.predict(headline)\n",
        "    return float(probValue)\n",
        "\n",
        "print(DATAMINERS_getClickbaitScore(\"Should You bring the money now\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9B6C4wuxvFE",
        "colab_type": "text"
      },
      "source": [
        "# Feature 6 : Spam Score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqyv5Tv2xvFE",
        "colab_type": "text"
      },
      "source": [
        "#### Function to simplify label classes\n",
        "\n",
        "* Original --\tTrue\n",
        "* True\t--\tTrue\n",
        "* Mostly-true\t-- True\n",
        "* Half-true\t-- True\n",
        "* Barely-true\t-- False\n",
        "* False\t-- False\n",
        "* Pants-fire\t-- False"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBT49ctBxvFF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "class SpamScoreFeature():\n",
        "    def __init__(self): \n",
        "        #load the dataset\n",
        "        columnNames = [\"encoded_label\", \"headline_text\", \"sensational_vector\"]\n",
        "        dataTrain = pd.read_csv('input_data/train_sensational_feature.csv', sep=',', header=None, names = columnNames)\n",
        "        dataTest = pd.read_csv('input_data/test_sensational_feature.csv', sep=',', header=None, names = columnNames)\n",
        "        dataTrain = dataTrain.loc[1:]\n",
        "        dataTest = dataTest.loc[1:]\n",
        "        \n",
        "        #load the spam dictionary\n",
        "        spam_dict = pd.read_csv('input_data/spam/spam_dict.csv', usecols= [1], names = ['spamword'], encoding='latin-1', error_bad_lines=False)\n",
        "        spam_dict = spam_dict.fillna(0)\n",
        "        spam_dict = spam_dict.iloc[1:]\n",
        "        spam_dict = spam_dict.drop_duplicates()\n",
        "\n",
        "        # spam_dict.head(5)\n",
        "        #Count vector for train data\n",
        "        spamcountV = CountVectorizer(vocabulary=list(set(spam_dict['spamword'])))\n",
        "        train_count = spamcountV.fit_transform(dataTrain['headline_text'])\n",
        "       \n",
        "   \n",
        "        self.logR_pipeline = Pipeline([\n",
        "            ('NBCV',spamcountV),\n",
        "            ('nb_clf',MultinomialNB())])\n",
        "\n",
        "        self.logR_pipeline.fit(dataTrain['headline_text'], dataTrain['encoded_label'])\n",
        "        predicted_LogR = self.logR_pipeline.predict(dataTest['headline_text'])\n",
        "        score = metrics.accuracy_score(dataTest['encoded_label'], predicted_LogR)\n",
        "        print(\"Spam Score Model Trained - accuracy:   %0.6f\" % score)\n",
        "        \n",
        "\n",
        "    def predict(self, text):\n",
        "        predicted = self.logR_pipeline.predict([text])\n",
        "        predicedProb = self.logR_pipeline.predict_proba([text])[:,1]\n",
        "        return bool(predicted), float(predicedProb)\n",
        "    \n",
        "    \n",
        "spamscore = SpamScoreFeature()\n",
        "spamscore.predict(\"Says the Annies List political group supports third-trimester abortions on demand.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gh3Ht90txvFH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def DATAMINERS_getSpamScore(text):  # return between 0 and 1, being 0 = True,  1 = Fake\n",
        "    #print(clickBait.predict(\"Should You bring the money now\"))\n",
        "    binaryValue, probValue = spamscore.predict(text)\n",
        "    return (float(probValue))\n",
        "\n",
        "print(DATAMINERS_getSpamScore(\"Says the Annies List political group supports third-trimester abortions on demand.\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLGZt9-WxvFI",
        "colab_type": "text"
      },
      "source": [
        "#### Read the input data files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iL5xmHEexvFI",
        "colab_type": "text"
      },
      "source": [
        "# Feature 7 : Author Credibility"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "K5TZ3aEqxvFJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataAllAuthorsVeracity = dataAll.copy()\n",
        "\n",
        "fakeZero = 0\n",
        "fakeOne = 0\n",
        "falseMoreThanOne = 0\n",
        "trueZero = 0\n",
        "trueOne = 0\n",
        "trueMoreThanOne = 0\n",
        "for index, row in dataAllAuthorsVeracity.iterrows():\n",
        "    authorsCount = len(row['authors'])\n",
        "    dataAllAuthorsVeracity.at[index, 'authors_count'] = len(row['authors'])\n",
        "    if (authorsCount == 0):\n",
        "        if (row['veracity'] == 1):\n",
        "            trueZero += 1\n",
        "        else:\n",
        "            fakeZero += 1\n",
        "    elif (authorsCount == 1):\n",
        "        if (row['veracity'] == 1):\n",
        "            trueOne += 1\n",
        "        else:\n",
        "            fakeOne += 1\n",
        "    elif (authorsCount > 1):\n",
        "        if (row['veracity'] == 1):\n",
        "            trueMoreThanOne += 1\n",
        "        else:\n",
        "            falseMoreThanOne += 1\n",
        "\n",
        "print(\"trueZeroAuthors=\", trueZero)\n",
        "print(\"fakeZeroAuthors=\", fakeZero)\n",
        "print(\"trueOneAuthors=\", trueOne)\n",
        "print(\"fakeOneAuthors=\", fakeOne)\n",
        "print(\"trueMoreThanOneAuthors=\", trueMoreThanOne)\n",
        "print(\"fakeMoreThanOneAuthors=\", falseMoreThanOne)\n",
        "\n",
        "columnsToRemove = ['authors', 'canonical_link', 'images', 'source','url', 'text', 'title']\n",
        "dataAllAuthorsVeracity = dataAllAuthorsVeracity.drop(columns=columnsToRemove)\n",
        "dataAllAuthorsVeracity.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Gb2atgVxvFL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataTrainAuthorsVeracity = dataTrain.copy()\n",
        "dataTestAuthorsVeracity = dataTest.copy()\n",
        "\n",
        "for index, row in dataTrainAuthorsVeracity.iterrows():\n",
        "    dataTrainAuthorsVeracity.at[index, 'authors_count'] = len(row['authors'])\n",
        "\n",
        "for index, row in dataTestAuthorsVeracity.iterrows():\n",
        "    dataTestAuthorsVeracity.at[index, 'authors_count'] = len(row['authors'])\n",
        "            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkasJ1zfxvFN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "X_train = dataTrainAuthorsVeracity['authors_count'].values.reshape(-1, 1)\n",
        "Y_train = dataTrainAuthorsVeracity['veracity'].values\n",
        "X_test = dataTestAuthorsVeracity['authors_count'].values.reshape(-1, 1)\n",
        "Y_test = dataTestAuthorsVeracity['veracity'].values.reshape(-1, 1)\n",
        "\n",
        "\n",
        "from sklearn import linear_model\n",
        "logClassifierAuthorsCount = linear_model.LogisticRegression(solver='liblinear', C=1, random_state=111)\n",
        "logClassifierAuthorsCount.fit(X_train, Y_train)\n",
        "predicted = logClassifierAuthorsCount.predict(X_test)\n",
        "\n",
        "from sklearn import metrics\n",
        "print(\"accuracy=\", metrics.accuracy_score(Y_test, predicted))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bS8UGCZ8xvFO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def DATAMINERS_getAuthorScore(numAuthors): # return between 0 and 1, being 0 = True,  1 = Fake\n",
        "    x = np.array(numAuthors).reshape(-1, 1)\n",
        "    predicted = logClassifierAuthorsCount.predict(x)\n",
        "    predicedProbTrue = logClassifierAuthorsCount.predict_proba(x)[:,1]\n",
        "    #return int(predicted), float(predicedProb)\n",
        "    return 1 - float(predicedProbTrue)\n",
        "\n",
        "print(DATAMINERS_getAuthorScore(4))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tP4DZzdUxvFP",
        "colab_type": "text"
      },
      "source": [
        "# Feature 8 : Source Reputation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKA8dU75xvFP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "dataFakeNewsSites = pd.read_csv(\"input_data/politifact-fakenews-sites.csv\")\n",
        "dataFakeNewsSites.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spg82EsnxvFQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataFakeNewsSites['type of site'].unique()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCVvHrwnxvFR",
        "colab_type": "text"
      },
      "source": [
        "As we can see, the sources are classified in different categories. Almost are all fake (fake news, parody,..) except the category 'some fake stories'. So let's hot encode those categories as 1 for fake news and 0.5 for some fake news."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7F1NwMCxxvFR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for index, row in dataFakeNewsSites.iterrows():\n",
        "    score = 1\n",
        "    if (row['type of site'] == 'some fake stories'):\n",
        "        score = 0.5\n",
        "    dataFakeNewsSites.at[index, 'fake_score'] = score\n",
        "\n",
        "dataFakeNewsSites.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTqYz-75xvFR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def DATAMINERS_getSourceReputationScore(source): # return between 0 and 1, being 0 = True,  1 = Fake\n",
        "    if (source == \"\"):\n",
        "        return 0\n",
        "    d = dataFakeNewsSites[dataFakeNewsSites['site name'].str.match(source)]\n",
        "    if (d['fake_score'].empty):\n",
        "        return 0\n",
        "    return int(d['fake_score'].values)\n",
        "\n",
        "\n",
        "DATAMINERS_getSourceReputationScore('24wpn')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNCZr--GxvFU",
        "colab_type": "text"
      },
      "source": [
        "# Feature 9 : Content Length"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpqoeCJ0xvFU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataAllBodyLength = dataAll.copy()\n",
        "for index, row in dataAllBodyLength.iterrows():\n",
        "    textLength = len(row['text'])\n",
        "    dataAllBodyLength.at[index, 'text_length'] = textLength\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "linearRegressionBodyLength = LinearRegression(fit_intercept=True)\n",
        "\n",
        "A = np.array(list(dataAllBodyLength.text_length))\n",
        "B = np.array(list(dataAllBodyLength.veracity))\n",
        "\n",
        "linearRegressionBodyLength.fit(A[:, np.newaxis], B)\n",
        "\n",
        "xfit = np.linspace(-1, max(dataAllBodyLength.text_length), 1000)\n",
        "yfit = linearRegressionBodyLength.predict(xfit[:, np.newaxis])\n",
        "\n",
        "plt.scatter(A, B, s=1, c=\"orange\")\n",
        "plt.plot(xfit, yfit);\n",
        "\n",
        "print(\"Model slope:    \", linearRegressionBodyLength.coef_[0])\n",
        "print(\"Model intercept:\", linearRegressionBodyLength.intercept_)\n",
        "print(\"R2 score:\", linearRegressionBodyLength.score(A[:, np.newaxis], B))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZIPNSo9xvFW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for index, row in dataTrain.iterrows():\n",
        "    textLength = len(row['text'])\n",
        "    dataTrain.at[index, 'text_length'] = textLength\n",
        "\n",
        "for index, row in dataTest.iterrows():\n",
        "    textLength = len(row['text'])\n",
        "    dataTest.at[index, 'text_length'] = textLength\n",
        "\n",
        "from sklearn import linear_model\n",
        "# from sklearn import linear_model\n",
        "\n",
        "logClassifierBodyLength = linear_model.LogisticRegression(solver='liblinear', C=17/1000, random_state=111)\n",
        "logClassifierBodyLength.fit(dataTrain['text_length'].values.reshape(-1, 1), dataTrain['veracity'].values)\n",
        "\n",
        "predicted = logClassifierBodyLength.predict(dataTest['text_length'].values.reshape(-1, 1))\n",
        "\n",
        "from sklearn import metrics\n",
        "print(metrics.accuracy_score(dataTest['veracity'].values.reshape(-1, 1), predicted))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5XbTliDxvFY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def DATAMINERS_getBodyLengthScore(length): # return between 0 and 1, being 0 = True,  1 = Fake\n",
        "    x = np.array(length).reshape(-1, 1)\n",
        "    predicted = logClassifierBodyLength.predict(x)\n",
        "    predicedProb = logClassifierBodyLength.predict_proba(x)[:,1]\n",
        "    #return int(predicted), float(predicedProb)\n",
        "    return 1 - float(predicedProb)\n",
        "\n",
        "print(DATAMINERS_getBodyLengthScore(12000))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RaBzEJX8xvFa",
        "colab_type": "text"
      },
      "source": [
        "# Feature 10 : Word Frequency"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qt2akdz4xvFa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import  LogisticRegression\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from nltk.stem.porter import *\n",
        "from sklearn import metrics\n",
        "\n",
        "class WordFrequency():\n",
        "\n",
        "    def __init__(self):        \n",
        "\n",
        "        columnNames = [\"id\", \"label\", \"statement\", \"subject\", \"speaker\", \"speaker_job_title\", \"state_info\", \"party_affiliation\", \"barely_true_counts\", \"false_counts\", \"half_true_counts\", \"mostly_true_counts\", \"pants_on_fire_counts\", \"context\"]\n",
        "        dataTrain = pd.read_csv('input_data/dataset/train.tsv', sep='\\t', header=None, names = columnNames)\n",
        "        dataValidate = pd.read_csv('input_data/dataset/valid.tsv', sep='\\t', header=None, names = columnNames)\n",
        "        dataTest = pd.read_csv('input_data/dataset/test.tsv', sep='\\t', header=None, names = columnNames)\n",
        "        \n",
        "        #dropping columns\n",
        "        columnsToRemove = ['id','subject', 'speaker', 'context','speaker_job_title', 'state_info', 'party_affiliation', 'barely_true_counts', 'false_counts', 'half_true_counts', 'mostly_true_counts', 'pants_on_fire_counts']\n",
        "        dataTrain = dataTrain.drop(columns=columnsToRemove)\n",
        "        dataValidate = dataValidate.drop(columns=columnsToRemove)\n",
        "        dataTest = dataTest.drop(columns=columnsToRemove)\n",
        "\n",
        "        def convertMulticlassToBinaryclass(r):\n",
        "            v = r['label']\n",
        "            if (v == 'true'):\n",
        "                return 'true'\n",
        "            if (v == 'mostly-true'):\n",
        "                return 'true'\n",
        "            if (v == 'half-true'):\n",
        "                return 'true'\n",
        "            if (v == 'barely-true'):\n",
        "                return 'false'\n",
        "            if (v == 'false'):\n",
        "                return 'false'\n",
        "            if (v == 'pants-fire'):\n",
        "                return 'false'\n",
        "        dataTrain['label'] = dataTrain.apply(convertMulticlassToBinaryclass, axis=1)\n",
        "        dataValidate['label'] = dataValidate.apply(convertMulticlassToBinaryclass, axis=1)\n",
        "        dataTest['label'] = dataTest.apply(convertMulticlassToBinaryclass, axis=1)\n",
        "        \n",
        "\n",
        "    \n",
        "        tfidfV = TfidfVectorizer(stop_words='english', min_df=5, max_df=30, use_idf=True, smooth_idf=True, token_pattern=u'(?ui)\\\\b\\\\w*[a-z]+\\\\w*\\\\b')\n",
        "        train_tfidf = tfidfV.fit_transform(dataTrain['statement'].values)\n",
        "        test_tfidf = tfidfV.fit_transform(dataTest['statement'].values)\n",
        "\n",
        "#         print('TF-IDF VECTORIZER')\n",
        "\n",
        "        ## Removing plurals for the tokens using PorterStemmer\n",
        "        stemmer = PorterStemmer()\n",
        "        tfidfVPlurals= tfidfV.get_feature_names()\n",
        "        tfidfVSingles= [stemmer.stem(plural) for plural in tfidfVPlurals]\n",
        "\n",
        "        # Applying Set to remove duplicates\n",
        "        tfidfVTokens = list(set(tfidfVSingles))\n",
        "#         print('TFIDFV Tokens')\n",
        "#         print(tfidfVTokens)\n",
        "\n",
        "        self.logR_pipeline = Pipeline([\n",
        "                ('LogRCV', tfidfV),\n",
        "                ('LogR_clf',LogisticRegression(solver='liblinear', C=32/100))\n",
        "                ])\n",
        "\n",
        "        self.logR_pipeline.fit(dataTrain['statement'],dataTrain['label'])\n",
        "        predicted_LogR = self.logR_pipeline.predict(dataTest['statement'])\n",
        "        score = metrics.accuracy_score(dataTest['label'], predicted_LogR)\n",
        "        print(\"Word Frequency Model Trained - accuracy:   %0.6f\" % score)\n",
        "        \n",
        "\n",
        "    def predict(self, text):\n",
        "        predicted = self.logR_pipeline.predict([text])\n",
        "        predicedProb = self.logR_pipeline.predict_proba([text])[:,1]\n",
        "        return bool(predicted), float(predicedProb)\n",
        "    \n",
        "    \n",
        "# wf = WordFrequency()\n",
        "# wf.predict(\"Says the Annies List political group supports third-trimester abortions on demand.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4o7e0jYxvFc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from ipynb.fs.full.m_wordfrequency import WordFrequency\n",
        "wordFrequency = WordFrequency()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u868Z4VmxvFd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def DATAMINERS_getWordFrequencyScore(text):  # return between 0 and 1, being 0 = True,  1 = Fake\n",
        "    #print(clickBait.predict(\"Should You bring the money now\"))\n",
        "    binaryValue, probValue = wordFrequency.predict(text)\n",
        "    return (1 - float(probValue))\n",
        "\n",
        "print(DATAMINERS_getWordFrequencyScore(\"Says the Annies List political group supports third-trimester abortions on demand.\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zR5c40wcxvFd",
        "colab_type": "text"
      },
      "source": [
        "# FINAL COMBINED MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrSVi4lGxvFd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import warnings\n",
        "# warnings.filterwarnings('ignore')\n",
        "\n",
        "def isFakeNews(text, headline=\"\", numAuthors = 0, source = \"\", party =\"\"):\n",
        "    accur = [0.84, 0.56, 0.95, 0.35,  0.1 ,0.54, 0.98, 0.71, 0.6, 1] # using the (normalized) accuracy as weigths\n",
        "    w = [float(i)/sum(accur) for i in accur]\n",
        "    sumW = 0\n",
        "    prob = []\n",
        "    prob.append(w[0] * DATAMINERS_getAuthorScore(numAuthors))\n",
        "    sumW += w[0]\n",
        "    if ( (headline != \"\") & (party != \"\")):\n",
        "        prob.append(w[1] * DATAMINERS_getPartyAffiliationScore(headline, party))\n",
        "        sumW += w[1]\n",
        "    if (headline != \"\"):\n",
        "        prob.append(w[2] * DATAMINERS_getClickbaitScore(headline))\n",
        "        sumW += w[2]\n",
        "    if (headline != \"\"):\n",
        "        prob.append(w[3] * DATAMINERS_getSentimentAnalysisScore(headline))\n",
        "        sumW += w[3]\n",
        "    if (headline != \"\"):\n",
        "        prob.append(w[4] * DATAMINERS_getLDATopicModellingScore(headline))\n",
        "        sumW += w[4]\n",
        "    if (headline != \"\"):\n",
        "        prob.append(w[5] * DATAMINERS_getSensationalismScore(headline))\n",
        "        sumW += w[5]\n",
        "    if (headline != \"\"):\n",
        "        prob.append(w[6] * DATAMINERS_getSpamScore(headline))\n",
        "        sumW += w[6]\n",
        "    prob.append(w[7] * DATAMINERS_getBodyLengthScore(len(text)))\n",
        "    sumW += w[7]\n",
        "    prob.append(w[8] * DATAMINERS_getWordFrequencyScore(text))\n",
        "    sumW += w[8]\n",
        "    if (party != \"\"):\n",
        "        prob.append(w[9] * DATAMINERS_getSourceReputationScore(source))\n",
        "        sumW += w[9]\n",
        "    \n",
        "    probTotal = sum(prob[0:len(prob)]) / sumW\n",
        "    return probTotal\n",
        "    \n",
        "result = isFakeNews(\"Yesterday, the Brazilian soccer team won the world cup by defeating Argentina\", \"World Cup ends\", 1, \"cnn.com\", \"republican\")\n",
        "\n",
        "if result > 0.5:\n",
        "    print(\"is FAKE NEWS!!!\")\n",
        "else:\n",
        "    print(\"it is NOT fake news!!!\")\n",
        "            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETx0Pdj0xvFe",
        "colab_type": "text"
      },
      "source": [
        "## Performance analysis "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "2Qf8wFb3xvFe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "truePos = 0\n",
        "trueNeg = 0\n",
        "falsePos = 0\n",
        "falseNeg = 0\n",
        "for index, row in dataTest.iterrows():\n",
        "    text = row['text']\n",
        "    headline= row['title']\n",
        "    numAuthors = len(row['authors'])\n",
        "    source = row['source']\n",
        "    party = \"\"\n",
        "    if 'party' in dataTest.columns:\n",
        "        party = row['party']\n",
        "    pred = isFakeNews(text, headline, numAuthors, source, party)\n",
        "    if ((row['veracity'] == 1) &  (pred < 0.5) ):\n",
        "        truePos += 1\n",
        "    elif ((row['veracity'] == 0) & (pred >= 0.5) ):\n",
        "        trueNeg += 1\n",
        "    elif ((row['veracity'] == 1) &  (pred >= 0.5) ):\n",
        "        falsePos += 1            \n",
        "    elif ((row['veracity'] == 0) &  (pred < 0.5) ):\n",
        "        falseNeg += 1\n",
        "        \n",
        "print(\"truePos=\", truePos)\n",
        "print(\"trueNeg=\", trueNeg)\n",
        "print(\"falsePos=\", falsePos)\n",
        "print(\"falseNeg=\", falseNeg)\n",
        "print(\"accuracy=\", (truePos/(truePos+falseNeg)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VC_Tp_5yxvFg",
        "colab_type": "text"
      },
      "source": [
        "If we add some error margin, let's say 10p.p to make our model only trust the results beyong that margin, we have:\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "_fOz1cMCxvFh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "errorMargin = 0.10\n",
        "ignored = 0\n",
        "truePos = 0\n",
        "trueNeg = 0\n",
        "falsePos = 0\n",
        "falseNeg = 0\n",
        "for index, row in dataTest.iterrows():\n",
        "    text = row['text']\n",
        "    headline= row['title']\n",
        "    numAuthors = len(row['authors'])\n",
        "    source = row['source']\n",
        "    party = \"\"\n",
        "    if 'party' in dataTest.columns:\n",
        "        party = row['party']\n",
        "    pred = isFakeNews(text, headline, numAuthors, source, party)\n",
        "\n",
        "    if (abs(0.5 - pred) < errorMargin):\n",
        "        ignored += 1\n",
        "    elif ((row['veracity'] == 1) &  (pred < 0.5) ):\n",
        "        truePos += 1\n",
        "    elif ((row['veracity'] == 0) & (pred >= 0.5) ):\n",
        "        trueNeg += 1\n",
        "    elif ((row['veracity'] == 1) &  (pred >= 0.5) ):\n",
        "        falsePos += 1            \n",
        "    elif ((row['veracity'] == 0) &  (pred < 0.5) ):\n",
        "        falseNeg += 1\n",
        "\n",
        "        \n",
        "print(\"truePos=\", truePos)\n",
        "print(\"trueNeg=\", trueNeg)\n",
        "print(\"falsePos=\", falsePos)\n",
        "print(\"falseNeg=\", falseNeg)\n",
        "print(\"ignored=\", ignored)\n",
        "print(\"accuracy=\", (truePos/(truePos+falseNeg)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpw_rdOBxvFh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}